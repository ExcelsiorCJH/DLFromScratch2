{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap02 - 자연어와 단어의 분산 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 자연어 처리란\n",
    "\n",
    "- 한국어와 영어 등 우리가 평소에 쓰는 말을 **자연어**(natural language)라고 한다.\n",
    "\n",
    "- 자연어처리(**NLP**, Natural Language Processing)은 '우리의 말을 컴퓨터에게 이해시키기 위한 기술(분야)'를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 시소러스(Thesaurus)\n",
    "\n",
    "- 시소러스는 유의어 사전으로, '뜻이 같은 단어(동의어)'나 '뜻이 비슷한 단어(유의어)'가 한 그룹으로 분류되어 있다.\n",
    "\n",
    "- 대표적인 시소러스로는 'WordNet'이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시소러스 문제점\n",
    "\n",
    "- 시대 변화에 대응하기 어렵다.\n",
    "    - 신조어, 단어의 의미 변화 등\n",
    "    \n",
    "    \n",
    "- 사람을 쓰는 비용이 크다.\n",
    "\n",
    "- 단어의 미묘한 차이를 표헌할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 통계 기반 기법\n",
    "\n",
    "- **말뭉치(corpus)** : 대량의 텍스트 데이터를 의미하며, NLP나 애플리케이션을 염두에 두고 수집된 텍스트 데이터를 말한다.\n",
    "\n",
    "- 통계 기반 기법의 목표는 말뭉치(corpus)에서 자동으로, 그리고 효율적으로 핵심을 추출하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 파이썬으로 말뭉치 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you say goodbye and i say hello .'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "\n",
    "text = text.lower()\n",
    "text = text.replace('.', ' .')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text.split(' ')\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단어에 ID를 부여하고, ID의 리스트로 이용할 수 있도록 해준다.\n",
    "\n",
    "- 딕셔너리를 이용해 단어 ID와 단어를 매핑한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = {}\n",
    "\n",
    "for word in words:\n",
    "    if word not in word_to_id:\n",
    "        new_id =  len(word_to_id)\n",
    "        word_to_id[word] = new_id\n",
    "        \n",
    "id_to_word = {id_: word for word, id_ in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 딕셔너리를 사용해, 단어 ID를 검색하거나, 반대로 단어 ID를 가지고 단어를 검색할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 목록 -> 단어 ID 목록으로 변경\n",
    "import numpy as np\n",
    "\n",
    "corpus = [word_to_id[word] for word in words]\n",
    "corpus = np.array(corpus)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/util.py -> preprocess 메서드 사용\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 1, 5, 6]),\n",
       " {'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6},\n",
       " {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 단어의 분산 표현\n",
    "\n",
    "- 단어의 분산 표현(distributional representation)은 단어를 고정 길이의 밀집 벡터(dense vector)로 표현한다.\n",
    "\n",
    "- 밀집 벡터는 대부분의 원소가 0이 아닌 실수로 이루어진 벡터를 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 분포 가설(Distributional Hypothesis)\n",
    "\n",
    "> 단어의 의미는 주변 단어에 의해 형성 된다.\n",
    "\n",
    "- 단어 자체에는 의미가 없고, 그 단어가 사용된 맥락(또는 문맥, context)이 해당 단어의 의미를 형성한다.\n",
    "\n",
    "```\n",
    "I drik beer. We drink wine.\n",
    "\n",
    "I guzzle beer. We guzzle wine.\n",
    "```\n",
    "\n",
    "- 위의 예시에서 'drink'와 'guzzle'의 주변 단어(context)인 'beer, wine'을 통해, 'drink, guzzle'이 비슷한 의미를 가지는 단어라고 짐작할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Window-based Context\n",
    "\n",
    "- 맥락(context)는 특정 단어를 중심에 둔 그 주변 단어를 말한다.\n",
    "\n",
    "- 맥락의 크기를 window size 라고 한다.\n",
    "\n",
    "- 일반적으로, 좌우로 똑같은 수의 단어를 맥락으로 사용하지만, 경우에 따라 왼쪽, 오른쪽만 사용할 수 있다.\n",
    "\n",
    "![](./images/window_size.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 동시발생 행렬(Co-occurrence Matrix)\n",
    "\n",
    "- 주변 단어를 '세어 보는(counting)' 방법\n",
    "\n",
    "- 특정 단어에 대해, 그 단어의 주변에 어떤 단어가 몇 번이나 등장하는지 카운팅하여 합치는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus: [0 1 2 3 4 1 5 6]\n",
      "id_to_word: {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print(f'corpus: {corpus}')\n",
    "print(f'id_to_word: {id_to_word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Co-occurrence Matrix 생성\n",
    "\n",
    "- `window size = 1`로 설정할 경우\n",
    "\n",
    "|      -       | you  | say  | goodbye | and  | i    | hello | .    |\n",
    "| ----------- | ---- | ---- | ------- | ---- | ---- | ----- | ---- |\n",
    "| **you**     | 0    | 1    | 0       | 0    | 0    | 0     | 0    |\n",
    "| **say**     | 1    | 0    | 1       | 0    | 1    | 1     | 0    |\n",
    "| **goodbye** | 0    | 1    | 0       | 1    | 0    | 0     | 0    |\n",
    "| **and**     | 0    | 0    | 1       | 0    | 1    | 0     | 0    |\n",
    "| **i**       | 0    | 1    | 0       | 1    | 0    | 0     | 0    |\n",
    "| **hello**   | 0    | 1    | 0       | 0    | 0    | 0     | 1    |\n",
    "| **.**       | 0    | 0    | 0       | 0    | 0    | 1     | 0    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.array([[0, 1, 0, 0, 0, 0, 0], \n",
    "              [1, 0, 1, 0, 1, 1, 0], \n",
    "              [0, 1, 0, 1, 0, 0, 0], \n",
    "              [0, 0, 1, 0, 1, 0, 0], \n",
    "              [0, 1, 0, 1, 0, 0, 0], \n",
    "              [0, 1, 0, 0, 0, 0, 1], \n",
    "              [0, 0, 0, 0, 0, 1, 0]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n",
      "[0 1 0 1 0 0 0]\n",
      "[0 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# ID가 0인 단어의 벡터 표현\n",
    "print(C[0])\n",
    "# ID가 4인 단어의 벡터 표현\n",
    "print(C[4])\n",
    "\n",
    "# \"goodbye\"의 벡터 표현\n",
    "print(C[word_to_id['goodbye']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/util.py\n",
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i  # left window_size\n",
    "            right_idx = idx + i  # right window_size\n",
    "\n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "                \n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 1\n",
    "vocab_size = len(id_to_word)\n",
    "\n",
    "C = create_co_matrix(corpus, vocab_size, window_size=1)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 벡터 간 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CuPy",
   "language": "python",
   "name": "cupy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
