{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap02 - 자연어와 단어의 분산 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 자연어 처리란\n",
    "\n",
    "- 한국어와 영어 등 우리가 평소에 쓰는 말을 **자연어**(natural language)라고 한다.\n",
    "\n",
    "- 자연어처리(**NLP**, Natural Language Processing)은 '우리의 말을 컴퓨터에게 이해시키기 위한 기술(분야)'를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 시소러스(Thesaurus)\n",
    "\n",
    "- 시소러스는 유의어 사전으로, '뜻이 같은 단어(동의어)'나 '뜻이 비슷한 단어(유의어)'가 한 그룹으로 분류되어 있다.\n",
    "\n",
    "- 대표적인 시소러스로는 'WordNet'이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시소러스 문제점\n",
    "\n",
    "- 시대 변화에 대응하기 어렵다.\n",
    "    - 신조어, 단어의 의미 변화 등\n",
    "    \n",
    "    \n",
    "- 사람을 쓰는 비용이 크다.\n",
    "\n",
    "- 단어의 미묘한 차이를 표헌할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 통계 기반 기법\n",
    "\n",
    "- **말뭉치(corpus)** : 대량의 텍스트 데이터를 의미하며, NLP나 애플리케이션을 염두에 두고 수집된 텍스트 데이터를 말한다.\n",
    "\n",
    "- 통계 기반 기법의 목표는 말뭉치(corpus)에서 자동으로, 그리고 효율적으로 핵심을 추출하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 파이썬으로 말뭉치 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you say goodbye and i say hello .'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "\n",
    "text = text.lower()\n",
    "text = text.replace('.', ' .')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text.split(' ')\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단어에 ID를 부여하고, ID의 리스트로 이용할 수 있도록 해준다.\n",
    "\n",
    "- 딕셔너리를 이용해 단어 ID와 단어를 매핑한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = {}\n",
    "\n",
    "for word in words:\n",
    "    if word not in word_to_id:\n",
    "        new_id =  len(word_to_id)\n",
    "        word_to_id[word] = new_id\n",
    "        \n",
    "id_to_word = {id_: word for word, id_ in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 딕셔너리를 사용해, 단어 ID를 검색하거나, 반대로 단어 ID를 가지고 단어를 검색할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 목록 -> 단어 ID 목록으로 변경\n",
    "import numpy as np\n",
    "\n",
    "corpus = [word_to_id[word] for word in words]\n",
    "corpus = np.array(corpus)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/util.py -> preprocess 메서드 사용\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 1, 5, 6]),\n",
       " {'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6},\n",
       " {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 단어의 분산 표현\n",
    "\n",
    "- 단어의 분산 표현(distributional representation)은 단어를 고정 길이의 밀집 벡터(dense vector)로 표현한다.\n",
    "\n",
    "- 밀집 벡터는 대부분의 원소가 0이 아닌 실수로 이루어진 벡터를 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 분포 가설(Distributional Hypothesis)\n",
    "\n",
    "> 단어의 의미는 주변 단어에 의해 형성 된다.\n",
    "\n",
    "- 단어 자체에는 의미가 없고, 그 단어가 사용된 맥락(또는 문맥, context)이 해당 단어의 의미를 형성한다.\n",
    "\n",
    "```\n",
    "I drik beer. We drink wine.\n",
    "\n",
    "I guzzle beer. We guzzle wine.\n",
    "```\n",
    "\n",
    "- 위의 예시에서 'drink'와 'guzzle'의 주변 단어(context)인 'beer, wine'을 통해, 'drink, guzzle'이 비슷한 의미를 가지는 단어라고 짐작할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Window-based Context\n",
    "\n",
    "- 맥락(context)는 특정 단어를 중심에 둔 그 주변 단어를 말한다.\n",
    "\n",
    "- 맥락의 크기를 window size 라고 한다.\n",
    "\n",
    "- 일반적으로, 좌우로 똑같은 수의 단어를 맥락으로 사용하지만, 경우에 따라 왼쪽, 오른쪽만 사용할 수 있다.\n",
    "\n",
    "![](./images/window_size.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 동시발생 행렬(Co-occurrence Matrix)\n",
    "\n",
    "- 주변 단어를 '세어 보는(counting)' 방법\n",
    "\n",
    "- 특정 단어에 대해, 그 단어의 주변에 어떤 단어가 몇 번이나 등장하는지 카운팅하여 합치는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus: [0 1 2 3 4 1 5 6]\n",
      "id_to_word: {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print(f'corpus: {corpus}')\n",
    "print(f'id_to_word: {id_to_word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Co-occurrence Matrix 생성\n",
    "\n",
    "- `window size = 1`로 설정할 경우\n",
    "\n",
    "|      -       | you  | say  | goodbye | and  | i    | hello | .    |\n",
    "| ----------- | ---- | ---- | ------- | ---- | ---- | ----- | ---- |\n",
    "| **you**     | 0    | 1    | 0       | 0    | 0    | 0     | 0    |\n",
    "| **say**     | 1    | 0    | 1       | 0    | 1    | 1     | 0    |\n",
    "| **goodbye** | 0    | 1    | 0       | 1    | 0    | 0     | 0    |\n",
    "| **and**     | 0    | 0    | 1       | 0    | 1    | 0     | 0    |\n",
    "| **i**       | 0    | 1    | 0       | 1    | 0    | 0     | 0    |\n",
    "| **hello**   | 0    | 1    | 0       | 0    | 0    | 0     | 1    |\n",
    "| **.**       | 0    | 0    | 0       | 0    | 0    | 1     | 0    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.array([[0, 1, 0, 0, 0, 0, 0], \n",
    "              [1, 0, 1, 0, 1, 1, 0], \n",
    "              [0, 1, 0, 1, 0, 0, 0], \n",
    "              [0, 0, 1, 0, 1, 0, 0], \n",
    "              [0, 1, 0, 1, 0, 0, 0], \n",
    "              [0, 1, 0, 0, 0, 0, 1], \n",
    "              [0, 0, 0, 0, 0, 1, 0]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n",
      "[0 1 0 1 0 0 0]\n",
      "[0 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# ID가 0인 단어의 벡터 표현\n",
    "print(C[0])\n",
    "# ID가 4인 단어의 벡터 표현\n",
    "print(C[4])\n",
    "\n",
    "# \"goodbye\"의 벡터 표현\n",
    "print(C[word_to_id['goodbye']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/util.py\n",
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i  # left window_size\n",
    "            right_idx = idx + i  # right window_size\n",
    "\n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "                \n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 1\n",
    "vocab_size = len(id_to_word)\n",
    "\n",
    "C = create_co_matrix(corpus, vocab_size, window_size=1)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 벡터 간 유사도\n",
    "\n",
    "- 벡터 간의 유사도를 측정하는 방법은 다양하다(e.g. 유클리드 거리, 맨하탄 거리 등)\n",
    "\n",
    "- 단어 벡터의 유사도를 나타낼 때는 **코사인 유사도**(cosine similarity)를 자주 사용한다.\n",
    "\n",
    "- 두 벡터 $\\mathbf{x} = (x_1, x_2, \\dots, x_n)$과 $\\mathbf{y}=(y_1, y_2, \\dots, y_n)$ 에 대하여 코사인 유사도는 다음과 같다.\n",
    "\n",
    "$$\n",
    "\\text{similarity}(\\mathbf{x}, \\mathbf{y}) = \\frac{\\mathbf{x} \\cdot \\mathbf{y}}{\\| \\mathbf{x} \\| \\| \\mathbf{y} \\|} = \\frac{x_1 y_1 + \\cdots + x_n y_n}{\\sqrt{x_{1}^{2} + \\cdots + x_n^{2}} \\sqrt{y_1^{2} + \\cdots + y_n^{2}}}\n",
    "$$\n",
    "\n",
    "- 위 식에서 분자에는 벡터의 내적, 분모에는 각 벡터의 노름(norm)이 등장한다.\n",
    "\n",
    "- 즉, 벡터를 정규화하고 내적을 구하는 것이라고 볼 수 있다.\n",
    "\n",
    "- 코사인 유사도를 직관적으로 보면, '두 벡터가 가리키는 방향이 얼마나 비슷한가' 이다. 두 방향이 완전히 같다면 1, 반대면 -1 이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    # epsilon 값을 추가해, \n",
    "    # 0으로 나누기 오류가 나는 것을 막아줌\n",
    "    nx = x / np.sqrt(np.sum(x**2) + eps)  # x의 정규화\n",
    "    ny = y / np.sqrt(np.sum(y**2) + eps)  # y의 정규화\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067758832467\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess, create_co_matrix, cos_similarity\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "c0 = C[word_to_id['you']]  # \"you\"의 단어 벡터\n",
    "c1 = C[word_to_id['i']]  # 'i'의 단어 벡터\n",
    "print(cos_similarity(c0, c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 유사 단어의 랭킹 표시\n",
    "\n",
    "검색어와 비슷한 단어를 유사도 순으로 출력하는 함수인 `most_similar()` 구현\n",
    "\n",
    "1. 검색어의 단어 벡터를 꺼낸다.\n",
    "\n",
    "2. 검색어의 단어 벡터와 다른 모든 단어 벡터와의 코사인 유사도를 각각 구한다.\n",
    "\n",
    "3. 계산한 코사인 유사도 결과를 기준으로 값이 높은 순서대로 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    # 1) 검색어를 꺼낸다.\n",
    "    if query not in word_to_id:\n",
    "        print(f'{query}(을)를 찾을 수 없습니다.')\n",
    "        return \n",
    "    \n",
    "    print(f'\\n[query] {query}')\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    # 2) 코사인 유사도 계산\n",
    "    vocab_size = len(id_to_word)\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "        \n",
    "    # 3) 코사인 유사도를 기준으로 내림차순으로 출력\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(f' {id_to_word[i]}: {similarity[i]}')\n",
    "        \n",
    "        count +=1\n",
    "        if count >= top:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy의 artsort() 예시\n",
    "# 오름차순\n",
    "x = np.array([100, -20, 2])\n",
    "x.argsort()\n",
    "\n",
    "# 내림차순\n",
    "(-x).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067758832467\n",
      " i: 0.7071067758832467\n",
      " hello: 0.7071067758832467\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess, create_co_matrix, most_similar\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "most_similar('you', word_to_id, id_to_word, C, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 통계 기반 기법 개선하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 상호정보량\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CuPy",
   "language": "python",
   "name": "cupy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
