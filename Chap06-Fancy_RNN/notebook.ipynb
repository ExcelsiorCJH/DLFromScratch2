{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap06 - 게이트가 추가된 RNN\n",
    "\n",
    "> [Chap05-순환신경망(RNN)](https://github.com/ExcelsiorCJH/DLFromScratch2/blob/master/Chap05-Recurrent_Neural_Network/notebook.ipynb)에서 살펴본 RNN 구조는 순환경로를 통해 과거의 정보를 기억할 수 있었다. 하지만, 실제로는 성능이 좋지 못한데 그 이유는 장기(long term)의존 관계를 잘 학습할 수 없기 때문이다.  이번 장에서는 이러한 RNN의 단점을 보완한 LSTM, GRU에 대해서 다룬다. LSTM이나 GRU에는 **'게이트'**(gate)라는 구조가 더해져 있는데, 이 게이트 덕분에 시계열 데이터의 장기 의존 관계를 학습할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 RNN의 문제점\n",
    "\n",
    "- RNN의 문제점은 시계열 데이터의 장기 으존 관계(long-term dependency)를 학습하기 어렵다.\n",
    "\n",
    "- 그 원인은 BPTT에서 기울기 소실 또는 기울기 폭발(vanishing & exploding gradient)이 일어나기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 RNN 복습\n",
    "\n",
    "<img src=\"./images/fig_6-1.png\" height=\"70%\" width=\"70%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RNN 계층은 시계열 데이터인 $\\mathbf{x}_{t}$를 입력하면 $\\mathbf{h}_{t}$를 출력한다. \n",
    "\n",
    "- $\\mathbf{h}_{t}$는 RNN 계층의 **은닉 상태(hidden state)**라고 하며, 과거 정보를 저장하는 역할을 한다.\n",
    "\n",
    "- RNN cell의 내부를 자세히 살펴보면 아래의 그림과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_6-2.png\" height=\"50%\" width=\"50%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 기울기 소실 또는 기울기 폭발\n",
    "\n",
    "<img src=\"./images/fig_6-3.png\" height=\"70%\" width=\"70%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 예시에서 `\"?\"`에 들어가는 단어는 \"Tom\"이다. \n",
    "\n",
    "- RNNLM이 이 문제에 올바르게 답하려면, \"Tom was watching TV in his room.\"과  \"Mary came into the room.\"이라는 정보를 기억해둬야 한다.\n",
    "\n",
    "- 즉, 이러한 정보를 RNN 레이어의 hidden state에 인코딩해 보관해둬야 한다.\n",
    "\n",
    "- 위의 예시에 대한 RNNLM의 BPTT는 아래의 그림과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_6-4.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 그림에서 RNN 레이어가 과거 방향으로 기울기(gradient)를 전달함으로써 시간 방향의 의존관계를 학습할 수 있게 된다.\n",
    "\n",
    "- 이때의 기울기는 (이론적으로) 학습해야 할 정보가 들어 있고, 그것을 과거로 전달함으로써 장기 의존 관계를 학습한다.\n",
    "\n",
    "- 하지만, 단순한 RNN(vanilla RNN) 레이어에서는 시간을 거슬러 올라갈수록 기울기가 작아지거나 커지는 문제가 발생한다(vanishing or exploding gradient)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 기울기 소실과 기울기 폭발의 원인\n",
    "\n",
    "<img src=\"./images/fig_6-5.png\" height=\"70%\" width=\"70%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 그림은 길이가 $T$인 시계열 데이터를 가정하여 $T$번째 정답 레이블로부터 전해지는 기울기가 어떻게 변화하는지 나타낸 그림이다.\n",
    "\n",
    "- 이때, 시간 방향 기울기(gradient)를 살펴보면, 역전파로 전해지는 기울기는 차례로 `'tanh'` → `'+'` → `'MatMul'` 연산을 통과한다. \n",
    "\n",
    "- `'+'`의 역전파는 상류에서 전해지는 기울기를 그대로 하류로 흘려보내기 때문에 기울기의 값이 변하지 않지만, `'tanh'`와 `'MatMul'`은 변하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tanh의 역전파\n",
    "\n",
    "$$\n",
    "y = \\tanh{(x)} = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\tanh{(x)}}{\\partial x} &= \\frac{( e^x + e^{-x})(e^x + e^{-x}) - ( e^x - e^{-x})( e^x - e^{-x})}{( e^x + e^{-x})^{2}} \\\\ \n",
    "&= 1 - \\frac{( e^x - e^{-x})( e^x - e^{-x})}{( e^x + e^{-x})^{2}} \\\\ \n",
    "&= 1 - \\left\\{ \\frac{( e^x - e^{-x})}{( e^x + e^{-x})} \\right\\}^{2} \\\\\n",
    "&= 1 - \\tanh{(x)}^{2} \\\\\n",
    "&= 1-y^{2}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_6-6.png\" height=\"40%\" width=\"40%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 그래프에서 점선이 $y=\\tanh{(x)}$의 미분이며, 그 값이 1.0 이하이고, $x$가 0으로 부터 멀어질수록 작아진다. \n",
    "\n",
    "- 따라서, 역전파에서 기울기가 $\\tanh$ 노드를 지날때 마다 값은 계속해서 작아지게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MatMul에서의 역전파\n",
    "\n",
    "<img src=\"./images/fig_6-7.png\" height=\"70%\" width=\"70%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 상류로부터 흘러온 기울기 $\\mathbf{dh}$ `'MatMul'`노드에서의 역전파는 $\\mathbf{dh} \\cdot \\mathbf{W_h}^{\\mathsf{T}}$라는 행렬 곱이 된다.\n",
    "\n",
    "- 이러한 행렬곱이 시계열 데이터의 time_step 만큼 반복한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.32971447 0.30503349 0.08888152]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmcHHWd//HXp3sucmeYyUFIMjm4AnJlEiASjnAIKCKXRpAEFRNB1/XaH+B6/FxQTldcEdyIIHiAHCIKIsiRECEEJwYlgQghyYQkQCYHyeSYycz0Z//omqQzzNWZqVT31Pv5sJ3qquqqT9q23/2t77eqzN0REZH4SkRdgIiIREtBICIScwoCEZGYUxCIiMScgkBEJOYUBCIiMacgEBGJOQWBiEjMKQhERGKuIOoCOqOsrMwrKiqiLkNEJK8sWLBgnbuXd7ReXgRBRUUFVVVVUZchIpJXzKy6M+vp0JCISMwpCEREYk5BICIScwoCEZGYUxCIiMScgkBEJOYUBCIiMdejg+CNd2u5Z96KqMsQEclpPToI5rxew7cfWcw7m+qiLkVEJGf16CA4dvS+AMxfvj7iSkREclePDoJDhvajb0kBLy5TEIiItCW0IDCzcjP7npld02L+4Wb2pJnNNbP7zaworBqSCeOYUaW8uGxDWLsQEcl7YbYIfgDUA4Ut5jtwtrtPBqqBc0KsgWNH78vydVvVTyAi0obQgsDdpwHPtTL/FXevD55uBLaGVQOon0BEpCOR9RGY2QeBQ4En2lg+w8yqzKyqpqZmj/ejfgIRkfbt9SCwtKuAKcA0d29qbT13n+Xule5eWV7e4X0V2pRMGBMr1E8gItKWKFoEnwfedvdr2gqB7qZ+AhGRtu21IDCzG4IRQmcDM81sdvD4atj7Vj+BiEjbQr1VpbvPBmYH01cGs88Kc5+tGbdfP/oWp/sJzjly2N7evYhITuvRJ5Q1SyaMiTqfQESkVbEIAtjVT/DuZvUTiIhkilUQABpGKiLSQmyCYFc/gQ4PiYhkik0QNPcTzFeLQERkN7EJAkgfHlqmfgIRkd3ELghA/QQiIpliFQTqJxAReb9YBYH6CURE3i9WQQDqJxARaSmWQQDqJxARaRa7IFA/gYjI7mIXBOonEBHZXeyCANRPICKSKbZBAOonEBGBmAaB+glERHaJZRCon0BEZJdYBgGon0BEpFmsgwDUTyAiEtsgUD+BiEhabINA/QQiImmxDQJQP4GICCgIAPUTiEi8xToI1E8gIgIFYW3YzMqBLwMpd/9Wxvw+wM+AYcAGYJq7bw6rjvYkE8YE9ROISMyF2SL4AVAPFLaY/xXgj+5+AvAX4PIQa+jQsaNL1U8gIrEWWhC4+zTguVYWTQEeCKYfAo4Lq4bOUD+BiMRdFH0Exe7eEEyvBwa2tpKZzTCzKjOrqqmpCa2YcUPVTyAi8RZFEKTMrHm/A4FWv+XdfZa7V7p7ZXl5eWjFFCQT6X6C5WoRiEg8RREE84FzgunzgaciqGE3x44uZVnNVtaqn0BEYmivBYGZ3WBmRcB1wAwzmw2MB+7aWzW0ZWc/wXIdHhKR+Alt+CiAu88GZgfTVwaz1wFnhrnfbO3qJ1jPR4/YL+pyRET2qlifUNasuZ9AI4dEJI4UBAH1E4hIXCkIAuonEJG4UhAEMvsJRETiREEQUD+BiMSVgiCD+glEJI4UBBnUTyAicaQgyKB+AhGJIwVBBvUTiEgcKQhaUD+BiMSNgqAF9ROISNwoCFpQP4GIxI2CoAX1E4hI3CgIWqF+AhGJEwVBK9RPICJxoiBohfoJRCROFAStUD+BiMSJgqAN6icQkbhQELRB/QQiEhcKgjaon0BE4kJB0Ab1E4hIXCgI2nHc6H1ZVrOVZTVboi5FRCQ0CoJ2nHPUfhQmjV++WB11KSIioVEQtGNQ3xLOPGwoD1atYmt9Y9TliIiEIrQgMLNrzGyOmT1vZodmzC8ys7vM7Bkz+5OZ9Q+rhu4wfVIFtfWN/G7h6qhLEREJRShBYGaTgcHufiIwE7gpY/EZwGp3nwL8DrgsjBq6y9EjBnDYsH7c88IK3D3qckREul1YLYLTgXsB3H0RUJqxrBYYGEyXATUh1dAtzIzpx1XwxtotzHtTI4hEpOcJKwgGsfsXfKOZNe/rr8AhZvYqcDHwcGsbMLMZZlZlZlU1NdFmxdlH7MfAXoXcPW9FpHWIiIQhrCDYxK5f/QApd08F098Hbnb3ccAlwKzWNuDus9y90t0ry8vLQyqzc0oKk0ydOIK/vPouqzZui7QWEZHuFlYQzAUuADCzccCqjGUjgXeC6bXA8JBq6FYXHzMCgF/PXxlxJSIi3SusIHgMKDKzucDNwJVmdoOZFQHfAm4ys2eB+4H/CKmGbrX/wF6cNm4w9720krqGpqjLERHpNgVhbDQ4DHR5i9lXBn//BZwSxn7DNv24Cp5Y/C5//McaLqzMi4aMiEiHdEJZFo4bsy8HDOrD3fM0lFREeg4FQRbMjGmTKli0ejN/X/le1OWIiHSLTgWBmR1vZneY2bPBGcGPm9lVZjYg7AJzzXlHDaNvcQH3zFsRdSkiIt2iwyAws1uBU4Hvu/vJwRnBHwWqgJ+a2TEh15hTehcXcEHl/vzplbdZW6u7l4lI/utMi+AWd///7r6seYa7N7j7U+4+lV1DQWPjkmNH0tDk3Dv/rahLERHpsg5HDbn7UgAzOwi4FOifsewKd4/dNZpHl/fhxAPL+fX8ai4/aQxFBepqEZH8lc032L3AAuDnGY/Ymj5pJGtr63licewaRCLSw2RzHsF6d38wtEryzEkHDmJEaS/ufmEFZx+xX9TliIjssWxaBLeZ2e1mNt3MppnZtNCqygOJhDHtuJFUVW9k0epNUZcjIrLHsgmCacAWoATYJ3jE2oXjh7NPYVJDSUUkr2VzaKjY3fPiukB7S/9ehXzsqGH87u+ruPrMQxjYuyjqkkREspZNi+BFM7vEzA4yswPN7MDQqsoj0yeNpL4xxW+rNJRURPJTNi2CUcFjSvDcgc90e0V55uAh/ThmVCm/nFfN5yaPJpmwqEsSEclKNi2CR9390xmP2IdAs0snVbD6ve08/dq7UZciIpK1bIIgp28yH6XTxg1maP8S7pkXu3PrRKQHyObQ0NtmNgeYDzQCuPs3QqkqzxQkE3zq2JHc9MS/WLq2lrGD+kZdkohIp2XTIrgb+Dbpu489ETwk8IkJwylKJtQqEJG80+kgcPc5wHqgDFgTPJdAWZ9iPnL4UB5asIrauoaoyxER6bROB4GZfR24lvTN5q83s0+HVlWemj6pgq07mnhowaqoSxER6bRsDg2dB5zr7rcAF5I+01gyHDF8AEcMH8A986pJpXQrSxHJD9kEQb0HN+oNbk6fDKek/HbppJEsW7eVvy5dF3UpIiKdkk0QLDKzb5rZkWZ2NbAkrKLy2VkfGEpZnyJdf0hE8kY2QfDvpO9GdhmwEbgilIryXHFBkk9OHMHTS9aycv22qMsREelQNqOGUsB9wA3AnwBdhL8NFx0zgoQZv5qvoaQikvuyGTV0IzAHuJF0GFzfwfrXmNkcM3vezA5tsezTZvZisOyUPSk8lw3tvw9nHDqE3/7tLbbvaIq6HBGRdmVzZvEUdx/fmRXNbDIw2N1PNLPDgJuAs4JlhwKTgUlBK6NHmnbcSB575W0eeXk1UyeOiLocEZE2ZdNHsMTMiju57umk73GMuy8CSjOWfRaoBp4xs/vNrCyLGvLGxFGlHDykL794YQXBYCsRkZyUTRAMJD1y6N7g8Zt21h0E1GQ8bzSz5n0dAKxz95OAB4DvtLYBM5thZlVmVlVTU9PaKjnNzLh0UgVL3qnVUFIRyWnZBMEVwKnAVcHj6nbW3UQ6OJqlMg4DNZLubAZ4FBjX2gbcfZa7V7p7ZXl5eRZl5o5zjx7G0P4l/PjppVGXIiLSpg6DwMxuNLO+7l7d8mFmk83s/FZeNhe4IHj9OCDzmgvzCPoLgJOAf3btn5C7iguSzDxhNC+t2MCLy9ZHXY6ISKs601k8C/ihmTUBi4FtwDDgINJf6re28prHgLPMbC5QC8w0sxuAbwG3AXeZ2YWkWw49+gY3UyeO4NZn3+TWZ5Zy7Oh9oy5HROR9OgwCd18KXGZmJaS//HsBT7v78nZekwIubzH7yuDvDtLXKoqFksIkM04Yxff/tIS/r9zI0SMGdvwiEZG9KJsTyupIDwmd114IyPtdfMxIBvYq5NZn1FcgIrmnU0FgZkkz60O6k1iy1Lu4gM8eP4pnlqxl0epNUZcjIrKbdoPAzF43s3nAGGB6xvwVZva4mall0EnTJlXQt6SAHz/zRtSliIjspqMWQTWwvZX5b7j7mYCOdXRSv5JCPj2pgicWv8u/3qmNuhwRkZ2yOY8gk06V3QOfOX4UvYuS3Pqs8lNEcseeBoHsgQG9irjkuAoe/eca3qzZEnU5IiJA14NALYMsXTZ5FMUFCW579s2oSxERAToOghqgifRJYJk/YceY2ePA6LAK66nK+hRz0cSR/P7l1bpxjYjkhHaDwN0vcvfT3P1Ud78bsGD+GHc/093H7pUqe5gZJ4wmacbtc9QqEJHoZXto6HvNE2Z2ejfXEhtD+pfw8Qn78+CCt1jzXmuDskRE9p5s7lA22t2fypilk8u64PMnjsEdZj23LOpSRCTmsmkR3NHiuXVnIXGz/8BenHf0MO59aSVra+uiLkdEYiybIGj5xa8RQ110xUljaWhK8TO1CkQkQln1EZjZtOAxveO1pSMVZb0558hh/OrFlWzYuiPqckQkprLtLG4kPZy0MYRaYukLJ4+hrrGJn/9VrQIRiUY2QeDu/ht3/7W7/zq0imJm7KC+nHXYUO5+oZpN2xqiLkdEYqijq48+bmZ/Ck4eO3Qv1RQ7Xzh5LFvqG/nFCyuiLkVEYqijE8rOdPezgr+DWyzWqKFuMm6/fpx6yGDufH45W+p11E1E9q6uXGvoex2vIp31b1PGsml7A7+cVx11KSISM3scBC1OLpMuOmL4AE44sJw75i5j2w61CkRk79FlqHPIl6aMZf3WHdz70ltRlyIiMaIgyCGVFaUcO7qU/53zJnUNTVGXIyIxoSDIMV+acgBra+t5YMGqqEsRkZhQEOSY48bsy/iRA/np7DfZ0ZiKuhwRiYHQgsDMrjGzOWb2vJm97xwEMxtsZtvMrCSsGvKRmfHFKWNZ/d52Hl6oVoGIhC+UIDCzycBgdz8RmAnc1MpqVwHrwth/vjvpwHIO378/t81+k8YmtQpEJFxhtQhOB+4FcPdFQGnmQjM7mvTVS3WBnVaYGV88eSzV67fxx3+uibocEenhwgqCQaTvd9ys0cwSAGbWC7ge+G57GzCzGWZWZWZVNTU17a3aI516yGAOHtKXW59ZqlaBiIQqrCDYBAzMeJ5y9+Zvsx8CN7j7pvY24O6z3L3S3SvLy8tDKjN3JRLGl089kDdrtnLbbN3bWETCE1YQzAUuADCzccCqYHoQMB74nJndB4wDfhFSDXnvjMOG8LEj9+NHT7/BguqNUZcjIj1UWEHwGFBkZnOBm4ErzewG4L3gV/5Ud58KvApcGlINPcJ/fewwhvYv4cu/XUhtnS5TLSLdL5QgcPeUu1/u7pODq5e+5e5XuvuOFuud5O66YW87+pUU8qOpR7LmvTq+88jiqMsRkR5IJ5TlgfEjS/m3KWP53cLVPPLy6qjLEZEeRkGQJ7548lgqRw7kmw8v4q0N26IuR0R6EAVBnihIJvjhJ44E4Cu/fVlDSkWk2ygI8sjw0l5ce+5hVFVv5CfPakipiHQPBUGeOefIYZx71DD+5xkNKRWR7qEgyEPfPedQDSkVkW6jIMhDmUNKv60hpSLSRQqCPNU8pPRhDSkVkS5SEOQxDSkVke6gIMhjGlIqIt1BQZDnNKRURLpKQdADaEipiHSFgqCH+K9zDmW/ARpSKiLZUxD0EH1LCrnlE0dpSKmIZE1B0IOMHzlQQ0pFJGsKgh5GQ0pFJFsKgh4mc0jplzWkVEQ6QUHQAzUPKV1QvZFbn10adTkikuMUBD3UziGlT7/BgwtWRV2OiOSwgqgLkPBc+7HDWFtbx9cf+AfvbdvBZZNHR12SiOQgtQh6sN7FBdx56QTOPGwI1z72Gjc9sQR3j7osEckxCoIerrggya0XHc0nJw7nJ8++yX/+fhFNKYWBiOyiQ0MxkEwY3z/3AwzoVcTts99k0/YGfvjxIykq0O8AEVEQxIaZceUZBzOwVyHf/9MSNm9v4KefGk/vYn0EROIutJ+EZnaNmc0xs+fN7NCM+Yeb2ZNmNtfM7jezorBqkPebccIYbrzgcJ5fuo6L75jPxq07oi5JRCIWShCY2WRgsLufCMwEbspY7MDZ7j4ZqAbOCaMGadvHK4dz+6fG8+rbm/n4/87jnU11UZckIhEKq0VwOnAvgLsvAkqbF7j7K+5eHzzdCGwNqQZpx4cOHcIvPj2BtzfVcf7tL7B8nf5nEImrsIJgEFCT8bzRzHbbl5l9EDgUeKK1DZjZDDOrMrOqmpqa1laRLpo0pox7P3cs2xuauPCnL7Bo9aaoSxKRCIQVBJuAgRnPU+6eArC0q4ApwDR3b2ptA+4+y90r3b2yvLw8pDLlA/v354HPH0dRMsEnZ73I/GXroy5JRPaysIJgLnABgJmNAzKvcfB54G13v6atEJC9a0x5Hx68fBKD+hUz7c6XeOrVd6MuSUT2orCC4DGgyMzmAjcDV5rZDcEIobOBmWY2O3h8NaQaJAv7DdiHBz4/iYOH9GXmrxbwkK5PJBIblg+XHKisrPSqqqqoy4iFLfWNzPxlFc8vXc+3PjKOzx4/KuqSRGQPmdkCd6/saD2dWiq76RNcn+iMQ4dwzaOvctMTS3RJCpEeTkEg71NckOQnFx/N1Anp6xOd85O/sqB6Q9RliUhIFATSqmTCuO68D/A/nzyKdbU7OP/2eXz1/pdZW6uTz0R6GgWBtMnM+OgR+/H0107kipPG8Og/3mbKzXO4Y+4yGnQLTJEeQ0EgHepdXMD/O+NgnvjKCUyoGMi1j73GmT+ay1/fWBd1aSLSDRQE0mmjynpz16cn8vPplTQ0pfjUz+dz+a8WsGrjtqhLE5Eu0DWIJWunHDKYD44t4465y7j12aU8+6+1XH7iWGaeOJqSwmTU5YlIltQikD1SUpjki1MO4OmvncQpBw/mh0+9zqn/PYcnF7+j22GK5BkFgXTJsAH78JOLj+Y3lx1Dr6IkM365gOl3/Y03a7ZEXZqIdJKCQLrFpLFlPPalyXzrI+NYWL2RM255jusef40t9Y1RlyYiHdAlJqTb1dTWc+Ofl/DAglWU9SnmExP25/yj92d0eZ+oSxOJlc5eYkJBIKFZuHIjP3r6DZ57vYaUw/iRA7lg/P58+PCh9CspjLo8kR5PQSA5493NdTy8cDUPLljF0rVbKC5IcMZhQ7hg/P5MGlNGMmFRlyjSIykIJOe4O/9ctYkHF6zikZdXs7mukaH9Szjv6GE6dCQSAgWB5LS6hiaefm0tDy54izk6dCQSCgWB5I13N9fx+4WreUCHjkS6lYJA8k5rh44G9yvmuNH7UllRysRRpYwt70NCwSDSKQoCyWvNh44ee2UNLy3fyLot9QAM6FVI5ciBVFaUMqGilA8M609RgU6HEWlNZ4NA1xqSnFRSmOTDhw/lw4cPxd2pXr+Nv63YwN9WbKBqxUaeem0tAMUFCY4cPoAJFaVMGFXK0SMG0Ff9CyJZUYtA8lJNbT0Lqjfw0vKNVFVvYPGazTSlnITBIUP7MaGilMqKgVSOLGVwv2LMdDhJ4keHhiRWttQ38vLK93hpxQaqVmxg4cr32N7QBEDf4gJGlfdmVFn6Mbq8D6PLelNR1ps+xWoUS8+lQ0MSK32KCzj+gDKOP6AMgIamFIvXbGbhyo0sX7eV5eu2UrViI3/4xxoyf/sM6lschENzUPRhVFlvRpT2Ut+DxIaCQHqkwmS67+DI4QN2m1/X0ET1+m0sX7eFZeu2srwmHRJPLn6X9Vt37FwvYTC8tBcV+/ZmcL9iyvsWU96nmPK+JenpvsWU9SmiT3GBDjtJ3lMQSKyUFCY5aEhfDhrS933LNm1rYPn6rSxft4XlNVtZtm4r1eu38a93alm3pZ7G1PsPo5YUJjJCojkwdoXFvn2K6FdSSL+SAvqWFFJSmFBwSM4JLQjM7BrghGAfM9x9cTC/D/AzYBiwAZjm7pvDqkOks/r3KuTIXu9vRQCkUs572xuoqa1PP7bU7ZquradmSz3L123lpeUb2Litoc19FCaNPsXpUOhbUhA80tP9WpnXt6SQfQqT7FOYpKQwQUlhMngk2KcwSUFSh6+k60IJAjObDAx29xPN7DDgJuCsYPFXgD+6+2/M7AvA5cANYdQh0l0SCaO0dxGlvYtabU1k2tGYYsPWHdTU1rNuSz2b6xrYXNdIbV0Dtbv9TU+/tWEbtXWNbK5rYEt9I9mM3yhIGPsUJikuTLJPUYKSgnRQpOelg6OoIEFRMkFh0ihMJihMJigqaPE8maAgeF6UTFBYsGtZQcJIZjwKEgmSCUgm0ssSZhQkg+UWrJPcNZ0wI5EwEgaJYJ41T1t6Wq2kaIXVIjgduBfA3ReZWWnGsinA9cH0Q8BPQ6pBJBJFBQmG9C9hSP+SrF+bSjlbdzTuFhTbG5qoa0hR19DE9oYm6oO/mfOap3c9b6K2rpGa2noamlI0NHnwN8WOxl3PWzvcFQUzSFo6NMzYGSDNgbHzL+nQSD8HIx0wtjNQdq2XMIP0f9LLg/0Y6XV37TtjWcZyCwqzjBph1/aap3dftmullst2W95yfsvXZ8y7dFIFpxwyOLs3NEthBcEgoCbjeaOZJdw9BRS7e3PbeT0wsLUNmNkMYAbAiBEjQipTJLckEhYcFto7J8WlUk5DKgiGxiAoguBobEpR35gi5U5jymnKeDSmnFSqeX6KphQ0plLvW6cp5aTcSXn6EiLp56TnZU77rvVSGa9pCoIq5Y4H6zrpbe187qS3T3ram/cXvI7dlqWnoXmaoAXmGc995/zmmMwcZt88mbmdlvN3Te+aj+/8r52v3f11ZMzb9ayhKfywDisINrH7F3wqCAGAVEYoDGT3wNjJ3WcBsyB9HkFIdYrEWiJhFCeSFBcAxVFXI1EJq6dpLnABgJmNA1ZlLJsPnBNMnw88FVINIiLSCWEFwWNAkZnNBW4GrjSzG8ysCLgOmGFms4HxwF0h1SAiIp0QyqGh4LDP5S1mXxn8XQecGcZ+RUQkexqELCIScwoCEZGYUxCIiMScgkBEJOYUBCIiMZcXN6Yxsxqgeg9fXkZ6pFJcxf3f31V6/7pO72HXdOX9G+nu5R2tlBdB0BVmVtWZO/T0VHH/93eV3r+u03vYNXvj/dOhIRGRmFMQiIjEXByCYFbUBUQs7v/+rtL713V6D7sm9Pevx/cRiIhI++LQIhARkXb06JvXm1k58GXS90P4VtT17G1m9grpm/8AzHL330RZTz5o+Zkxs4OA24AS4AV3/49IC8xxrbx/lwBXA2uBHe5+eqQF5jgzG0D6ro1DSP9Qnw4UEfJnsEcHAfADYCnQK+pCIvKuu58adRF5puVn5hbgs+6+wsweMLNj3H1+dOXlvJbv3wDgand/JLqS8kov4KvuvsbMPgx8HRhNyJ/BHn1oyN2nAc9FXUeEUh2vIpkyPzNmVgCUuPuKYPFDwHERlZYXWvn/3ABgY0Tl5B13X+Pua4KnG4F69sJnsEcHQZyZWW9gjJk9Z2b3m9nwqGvKQ+XsOrQG7dxjW9pUANxoZnOD+5BLJ5jZMNKtgR+wFz6DPf3QUGy5+1ZgDICZnUb6A/XxSIvKP++R/kXbrM17bEvr3P07wHfMrBfwiJk97+6Lo64rl5nZR4Czgc8B29gLn0G1CHooM0tmPNWX1x5w9+1AcfDrDOA84OkIS8o7weE1gO1ALaDx6u0ws8OBs919pruv31ufQbUIeq6xZnYnsCN4tLx1qHTOV4EHzawe+IO7vxZ1QXnmOjObSPq75mF3fzXqgnLcGcDk4J7uACvZC59BnVAmIhJzOjQkIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyCQnGdmw8ysw1v1mdkvQ67j7DC3LxIVBYHkHDP7c4tZB5AeX928/Dozmx08XjezmcGidm/SbWb/aWZPtXgsNLMvZ6wzLGPbs83sLTNrvrbLF7rj3yeSa3RCmeSiovYWuvvVzdNmdg8wpzMbdffvAd/LnGdmZwAHZ6yzGjgpY/ljwButbc/M/pv05YG3AP3d/V/BGaAXuvstnalpT5hZf2CUu7+c5ev2JX011UvdvSmU4iQvqUUgOcXMDKg0s3bDIFh3PNDH3ZdkzJtqZgdkudtWz6oMvnCT7r6ulWWHAZvdfSnp1srJkA6SMEMgcBQwNdsXuft64Fng4m6vSPKaWgSSa04DVgHnAr9tayUzO4T0hfQ+2ZmNBhc9mw00Bo+G4G8pcGcbL7sG+FEby6YCdwZhdBWQMLPRpFsI17v7VDP7BbAcOJb05YTvAa4AyoBPuvtrwWGn60j/KHvS3a9tUXcJcDcwDNgEzCD9q77UzPZz92nBVT0vCbZxrbs/Huy7GpgE7At8w93/DNwHPBjUIgIoCCSHBBco+xLwIeAuM3vc3Te3WKcE+DzwUeAid387c7m739fatt19GzCxlX1eBCRbmX8psM3dH2+j3OHuvixY93rS14z/qZlVtFhvhbt/18xuBj7k7qea2YXAdDO7GrgZONPdN5vZfWY20t2rM15/EOk7ex1vZgl3TwV9Gme4+1XBHdROB04ACoEngeaa17v7acEhoSeBP7v7tiAURXZSEEhOCELgduAOd3/LzL5B+kJbF7Wy+jrgtG46zj2Q9K/25jr6AN8kfenfK9p5XWcv0vVS8Hcp6VYBwf5OId25fSDwh/QRMQYA+5P+JZ/eifs/zOwZM/sx8BjQsiP9iODxbPB8cMYVP/8SbGO9mdWbmbkuLiatUBBIrtgPeNrdfw/g7i+Z2Tdp8YXr7nXAr8zsYdKHjzKXnUEbzOzXpA+vtDQc2Gxm09x9KukRSv/sxP2dm8xPr6sLAAABOUlEQVSsyN13AE1AcRvreRvTkA60JcDp7r7DzHoFLZfMukuAX7j7XWb2VzN7scX+XgfmuPtlwfq93L0xCJaJwGtmNhJoVAhIWxQEkhPcfSXpS+5mznsJIPhSa2mfLLffqQ5Sd18ILOzEqs+THl30JDAPeDS4cfsdWdSUMrMbgefMrJZ0S6HlXbwOBmaZ2RZgsbu/Z2avAD8xszvd/TNmttLM5gGbgUeBHwevPSpoUfUC/h0g6Eh/vbM1SjzoMtSS88zsJOD4zI7U4FyDklZW/5q7Lwipjj83tzrMbB9glrtfEsa+uiroLL4+c0RVMP824BZ3VxjITgoCkT1kZscA72bcWDxntBYEZjYAODYYPSSyk4JARCTmdEKZiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJARCTm/g8kKje8iG1FyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# chap06/rnn_gradient_graph.py\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "font_path = 'C:/Windows/Fonts/malgun.ttf'\n",
    "font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "plt.rc('font', family=font_name)\n",
    "\n",
    "\n",
    "N = 2  # 미니배치 크기\n",
    "H = 3  # hidden state 벡터의 차원 수\n",
    "T = 20  # 시계열 데이터의 길이(= timestep)\n",
    "\n",
    "dh = np.ones((N, H))\n",
    "np.random.seed(3)\n",
    "# Wh = np.random.randn(H, H) \n",
    "Wh = np.random.randn(H, H) * 0.5 \n",
    "\n",
    "norm_list = []\n",
    "for t in range(T):\n",
    "    dh = np.matmul(dh, Wh.T)\n",
    "    norm = np.sqrt(np.sum(dh**2)) / N\n",
    "    norm_list.append(norm)\n",
    "    \n",
    "u, s, vh = np.linalg.svd(Wh)\n",
    "print(s)\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.plot(np.arange(len(norm_list)), norm_list)\n",
    "plt.xticks([0, 4, 9, 14, 19], [1, 5, 10, 15, 20])\n",
    "plt.xlabel('시간 크기(time step)')\n",
    "plt.ylabel('노름(norm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.4 기울기 폭발 대책\n",
    "\n",
    "- 기울기 폭발(exploding gradient) 해결책으로는 **기울기 클리핑(gradients clipping)**이라는 기법이 있다.\n",
    "\n",
    "- 기울기 클리핑 알고리즘을 의사코드로 나타내면 다음과 같다.\n",
    "\n",
    "$$\n",
    "\\text{if } \\left\\| \\hat{g} \\right\\| \\ge threshold:\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{g} = \\frac{threshold}{\\left\\| \\hat{g} \\right\\|} \\hat{g}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 식에서 $\\hat{g}$는 신경망에서 사용되는 모든 매개변수의 기울기를 하나로 모은 것이다.\n",
    "    - 예를 들어, $\\mathbf{W}_{1}$과 $\\mathbf{W}_{2}$ 매개변수에 대한 기울기 $\\mathbf{dW}_{1}$과 $\\mathbf{dW}_{2}$를 결합(제곱의 합)한 것이다.\n",
    "    \n",
    "\n",
    "- 위의 식에서 $\\left\\| \\hat{g} \\right\\|$(기울기 L2 노름)가 $threshold$ 값을 초과하면 두 번째 수식과 같이 기울기를 수정한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chap06/clip_grads.py\n",
    "import numpy as np\n",
    "\n",
    "dW1 = np.random.rand(3, 3) * 10\n",
    "dW2 = np.random.rand(3, 3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0  # threshold\n",
    "\n",
    "def clip_grads(grds, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    \n",
    "    total_norm = np.sqrt(total_norm)\n",
    "    \n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: [2.77977507 4.54622076 2.05410345 2.01378711 5.1403506  0.87229369\n",
      " 4.83585532 3.62176212 7.07686622]\n",
      "after: [0.66651711 1.09006443 0.4925201  0.4828533  1.23252117 0.20915313\n",
      " 1.15951119 0.86840351 1.69684679]\n"
     ]
    }
   ],
   "source": [
    "print('before:', dW1.flatten())\n",
    "clip_grads(grads, max_norm)\n",
    "print('after:', dW1.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 기울기 소실과 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 LSTM의 인터페이스\n",
    "\n",
    "- 아래의 그림과 같이 $\\tanh{\\left( \\mathbf{h}_{t-1} \\mathbf{W}_{\\mathbf{h}} + \\mathbf{x}_{t} \\mathbf{W}_{\\mathbf{x}} + \\mathbf{b} \\right)}$ 를 `tanh`노드로 나타내어 간소화한 것이다.\n",
    "\n",
    "<img src=\"./images/fig_6-10.png\" height=\"70%\" width=\"70%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RNN Cell과 LSTM Cell을 간단하게 비교하면 아래의 그림처럼 나타낼 수 있다.\n",
    "\n",
    "<img src=\"./images/fig_6-11.png\" height=\"70%\" width=\"70%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 그림에서 보듯 LSTM 계층에는 $\\mathbf{c}$라는 경로가 있다는 것이 RNN과의 차이다. \n",
    "\n",
    "- $\\mathbf{c}$를 **기억 셀**(memory cell)이라고 하며, LSTM의 기억 메커니즘이다.\n",
    "\n",
    "- memory cell의 특징은 LSTM 계층 내에서만 주고받는다는 것이다.\n",
    "    - 다른 계층으로는 출력하지 않는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 LSTM 계층 조립하기\n",
    "\n",
    "- $\\mathbf{c}_{t}$에는 timestep $t$에서의 LSTM의 기억이 저장되어 있는데, 과거로 부터 $t$까지에 필요한 모든 정보가 저장되어 있다고 가정한다.\n",
    "\n",
    "- 이러한 기억 $\\mathbf{c}_{t}$를 바탕으로 특정 연산을 거친 후 외부 계층과 다음 timestep $t+1$의 LSTM에 hidden state $\\mathbf{h}_{t}$를 출력한다. \n",
    "     - 이때 출력하는 $\\mathbf{h}_{t}$는 아래의 그림처럼 memory cell $\\mathbf{c}_{t}$의 값을 $\\tanh$ 함수로 변환한 값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_6-12.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- memory cell $\\mathbf{c}_{t}$와 hidden state $\\mathbf{h}_{t}$의 관계는 $\\mathbf{c}_{t}$의 각 원소에 $\\tanh$ 함수를 적용한 것이다. \n",
    "\n",
    "- 즉, $\\mathbf{c}_{t}$와 $\\mathbf{h}_{t}$의 원소수는 같다는 뜻이고, 예를 들어, $\\mathbf{c}_{t}$의 원소 수가 100개면 $\\mathbf{h}_{t}$의 원소 수도 100개가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 게이트(gate)의 개념\n",
    "\n",
    "- 게이트는 **데이터의 흐름**을 **제어(control)**하는 역할을 한다.\n",
    "\n",
    "- 아래의 그림처럼 게이트의 열림 상태는 `0.0 ~ 1.0` 사이의 실수로 나타나며, '게이트를 얼마나 열까'라는 것도 데이터로 부터 (자동으로) 학습 한다.\n",
    "\n",
    "- 게이트의 열림 상태를 구할 때는 `sigmoid` 함수를 사용하는데, `sigmoid`함수의 출력이 0.0 ~ 1.0의 실수이기 떄문이다.\n",
    "\n",
    "<img src=\"./images/fig_6-14.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM의 게이트들\n",
    "\n",
    "<img src=\"./images/lstm.PNG\" height=\"80%\" width=\"80%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 output 게이트\n",
    "\n",
    "\n",
    "- output 게이트는 hidde state($\\mathbf{h}_{t}$)의 출력을 담당한다.\n",
    "\n",
    "- output 게이트는 $\\tanh{(\\mathbf{c}_{t})}$의 각 원소에 대해 '그것이 다음 timestep의 hidde state($\\mathbf{h}_{t}$)에 얼마나 중요한가'를 제어한다.\n",
    "\n",
    "- output 게이트의 열림 상태는 입력 $\\mathbf{x}_{t}$와 이전 상태 $\\mathbf{h}_{t-1}$로 부터 구한다. 아래의 식에서 $\\sigma {()}$는 시그모이드 함수를 의미한다.\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{o} = \\sigma \\left( \\mathbf{x}_{t}\\mathbf{W}_{\\mathbf{x}}^{(o)} + \\mathbf{h}_{t-1} \\mathbf{W}_{\\mathbf{h}}^{(o)} + \\mathbf{b}^{(o)} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_6-15.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 그림에서 output 게이트의 열림 상태를 계산한 $\\mathbf{o}$는 $\\tanh{\\mathbf{c}_{t}}$의 원소별 곱(element-wise, point-wise, 또는 아다마르 곱)을 통해 $\\mathbf{h}_{t}$를 구하게 된다.\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_{t} = \\mathbf{o} \\odot \\tanh{(\\mathbf{c}_{t})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - $\\tanh$의 출력은 `-1.0 ~ 1.0`의 실수이다. 이 `-1.0 ~ 1.0`의 수치를 그 안에 인코딩된 **'정보'**의 강약(정도)를 표시한다고 해석할 수 있다.\n",
    "- 시그모이드 함수의 출력은 `0.0 ~ 1.0`의 실수이며, 데이터를 얼만큼 통과시킬지를 정하는 비율을 뜻한다.\n",
    "- 따라서, 게이트에서는 시그모이드 함수가 사용되고, 실질적인 '정보'를 지니는 데이터에는 $\\tanh$함수가 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 forget 게이트\n",
    "\n",
    "- forget 게이트는 memory cell에 '무엇을 잊을지'를 제어하는 역할을 한다.\n",
    "\n",
    "$$\n",
    "\\mathbf{f} = \\sigma \\left( \\mathbf{x}_{t} \\mathbf{W}_{x}^{(\\mathbf{f})} + \\mathbf{h}_{t-1} \\mathbf{W}_{\\mathbf{h}}^{(\\mathbf{f})} + \\mathbf{b}^{(\\mathbf{f})} \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "- 위의 식에서 구한 $\\mathbf{f}$와 이전 memory cell인 $\\mathbf{c}_{t-1}$과의 원소별 곱, $\\mathbf{c}_{t} = \\mathbf{f} \\odot \\mathbf{c}_{t-1}$을 계산하여 $\\mathbf{c}_{t}$를 구한다.\n",
    "\n",
    "- forget 게이트를 LSTM 레이어에 추가하면 아래의 그림과 같다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_6-16.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.5 새로운 기억 셀\n",
    "\n",
    "- 6.2.4에서 forget 게이트를 통해 $t-1$ 시점의 memory cell로 부터 잊어야할 기억을 제어했다.\n",
    "\n",
    "- 이번에는 memory cell에 새로 기억해야할 정보를 아래의 그림과 같이 `tanh` 노드를 추가해 준다.\n",
    "\n",
    "- `tanh`노드가 계산한 결과를 이전 시각의 memory cell $\\mathbf{c}_{t-1}$에 더해짐으로써 새로운 '정보'가 추가된다.\n",
    "\n",
    "- 여기서 `tanh` 노드는 '게이트'가 아니며 단지 새로운 '정보'를 memory cell에 추가하는 것이 목적이다. \n",
    "\n",
    "$$\n",
    "\\mathbf{g} = \\tanh{\\left( \\mathbf{x}_{t} \\mathbf{W}_{x}^{(\\mathbf{g})} + \\mathbf{h}_{t-1} \\mathbf{W}_{h}^{(\\mathbf{g})} + \\mathbf{b}^{(\\mathbf{g})} \\right)}\n",
    "$$\n",
    "\n",
    "- 위에서 계산한 $\\mathbf{g}$(엄밀하게 말하면 $\\mathbf{g}$를 제어하는 input 게이트 $\\mathbf{i}$와의 원소 곱의 결과)가 이전 $t-1$ 시점의 $\\mathbf{c}_{t-1}$에 더해짐으로써 새로운 기억이 생겨난다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_6-17.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.6 input 게이트\n",
    "\n",
    "- input 게이트는 $\\mathbf{g}$의 각 원소가 새로 추가되는 정보로써의 가치가 얼마나 큰지를 판단하는 역할을 한다.\n",
    "\n",
    "- 즉, 새로운 정보($\\mathbf{g}$)를 바로 더해주는 것이 아니라, input 게이트에 의해 가중된 정보가 새로 추가되는 것이다.\n",
    "\n",
    "$$\n",
    "\\mathbf{i} = \\sigma{\\left( \\mathbf{x}_{t} \\mathbf{W}_{x}^{(\\mathbf{i})} + \\mathbf{h}_{t-1} \\mathbf{W}_{h}^{(\\mathbf{i})} + \\mathbf{b}^{(\\mathbf{i})} \\right)}\n",
    "$$\n",
    "\n",
    "- 위에서 계산한 $\\mathbf{i}$와 $\\mathbf{g}$의 원소별 곱 결과를 memory cell에 더해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_6-18.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.7 LSTM의 기울기 흐름\n",
    "\n",
    "<img src=\"./images/fig_6-19.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 그림처럼, memory cell의 역전파에서는 '$+$'와 '$\\times$' 노드만을 지나게 된다.\n",
    "\n",
    "- '$+$' 노드는 상류에서 전해지는 기울기를 그대로 흘러보내기 때문에 기울기 변화(감소)는 일어나지 않는다.\n",
    "\n",
    "- '$\\times$' 노드는 '행렬 곱'이 아닌 '원소별 곱(아마다르 곱)'을 계산한다. \n",
    "\n",
    "- '행렬 곱'이 아닌 '원소별 곱'이 이뤄지고, 매 timestep 마다 다른 게이트 값을 이용해 원소별 곱을 계산한다.\n",
    "    - 매번 새로운 게이트 값을 이용하기 때문에 곱셈의 효과가 누적되지 않아 기울기 소실이 일어나지 않게 되는 것이다.\n",
    "\n",
    "\n",
    "- '$\\times$' 노드의 계산은 forget 게이트가 제어한다. \n",
    "    - forget 게이트가 '잊어야 한다'(값이 0에 가까운 경우)고 판단한 memory cell의 원소에 대해서는 기울기가 작아진다.\n",
    "    - forget 게이트가 '잊어서는 안된다' (값이 1에 가까운 경우)고 판단한 원소에 대해서는 기울기가 약화되지 않은채로 과거 방향으로 전해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LSTM은 Long Short-Term Memory의 약자이며, **단기 기억**(short-term memory)을 **긴**(lon)시간 지속할 수 있음을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 LSTM 구현\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{f} &= \\sigma \\left( \\mathbf{x}_{t} \\mathbf{W}_{x}^{(\\mathbf{f})} + \\mathbf{h}_{t-1} \\mathbf{W}_{\\mathbf{h}}^{(\\mathbf{f})} + \\mathbf{b}^{(\\mathbf{f})} \\right) \\\\\n",
    "\\mathbf{g} &= \\tanh{\\left( \\mathbf{x}_{t} \\mathbf{W}_{x}^{(\\mathbf{g})} + \\mathbf{h}_{t-1} \\mathbf{W}_{h}^{(\\mathbf{g})} + \\mathbf{b}^{(\\mathbf{g})} \\right)}\\\\\n",
    "\\mathbf{i} &= \\sigma{\\left( \\mathbf{x}_{t} \\mathbf{W}_{x}^{(\\mathbf{i})} + \\mathbf{h}_{t-1} \\mathbf{W}_{h}^{(\\mathbf{i})} + \\mathbf{b}^{(\\mathbf{i})} \\right)} \\\\\n",
    "\\mathbf{o} &= \\sigma \\left( \\mathbf{x}_{t}\\mathbf{W}_{\\mathbf{x}}^{(o)} + \\mathbf{h}_{t-1} \\mathbf{W}_{\\mathbf{h}}^{(o)} + \\mathbf{b}^{(o)} \\right)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{c}_{t} = \\mathbf{f} \\odot \\mathbf{c}_{t-1} + \\mathbf{g} \\odot \\mathbf{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{h}_{t} = \\mathbf{o} \\odot \\tanh{(\\mathbf{c}_{t})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 식에서 $\\mathbf{f}, \\mathbf{g}, \\mathbf{i}, \\mathbf{o}$는 활성화 함수안에 아핀(affine)변환을 가지고 있다. 이 식을 아래의 그림처럼 하나의 식으로 정리해서 계산할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_6-20.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_6-22.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSTM 계산 그래프는 아래의 그림과 같다.\n",
    "\n",
    "<img src=\"./images/fig_6-21.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 그림에서 `slice` 노드의 순전파와 역전파는 아래의 그림과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_6-23.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.np import *\n",
    "from common.layers import *\n",
    "from common.functions import sigmoid\n",
    "\n",
    "\n",
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        Wx: 입력 x에 대한 가중치 매개변수(4개분의 가중치가 담겨 있음)\n",
    "        Wh: 은닉 상태 h에 대한 가장추 매개변수(4개분의 가중치가 담겨 있음)\n",
    "        b: 편향（4개분의 편향이 담겨 있음）  \n",
    "        '''\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "        \n",
    "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
    "        \n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "        \n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "        \n",
    "        c_next = f * c_prev + g * i  # Ct\n",
    "        h_next = o * np.tanh(c_next)\n",
    "        \n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "    \n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "        \n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "        \n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "        \n",
    "        dc_prev = ds * f\n",
    "        \n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "        \n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= (1 - g ** 2)\n",
    "        \n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "        \n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "        \n",
    "        return dx, dh_prev, dc_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Time LSTM 구현\n",
    "\n",
    "<img src=\"./images/fig_6-24.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_6-25.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        \n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 LSTM을 사용한 언어 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chap06/rnnlm.py\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Rnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 10001.06\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 5[s] | 퍼플렉서티 2989.65\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 10[s] | 퍼플렉서티 1227.51\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 15[s] | 퍼플렉서티 988.28\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 20[s] | 퍼플렉서티 784.42\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 25[s] | 퍼플렉서티 664.91\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 30[s] | 퍼플렉서티 642.07\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 35[s] | 퍼플렉서티 609.33\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 40[s] | 퍼플렉서티 574.94\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 45[s] | 퍼플렉서티 581.32\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 50[s] | 퍼플렉서티 502.83\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 55[s] | 퍼플렉서티 500.56\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 61[s] | 퍼플렉서티 447.93\n",
      "| 에폭 1 |  반복 261 / 1327 | 시간 66[s] | 퍼플렉서티 459.48\n",
      "| 에폭 1 |  반복 281 / 1327 | 시간 71[s] | 퍼플렉서티 449.69\n",
      "| 에폭 1 |  반복 301 / 1327 | 시간 76[s] | 퍼플렉서티 400.87\n",
      "| 에폭 1 |  반복 321 / 1327 | 시간 81[s] | 퍼플렉서티 345.39\n",
      "| 에폭 1 |  반복 341 / 1327 | 시간 86[s] | 퍼플렉서티 404.91\n",
      "| 에폭 1 |  반복 361 / 1327 | 시간 91[s] | 퍼플렉서티 404.37\n",
      "| 에폭 1 |  반복 381 / 1327 | 시간 96[s] | 퍼플렉서티 333.72\n",
      "| 에폭 1 |  반복 401 / 1327 | 시간 101[s] | 퍼플렉서티 348.93\n",
      "| 에폭 1 |  반복 421 / 1327 | 시간 106[s] | 퍼플렉서티 343.47\n",
      "| 에폭 1 |  반복 441 / 1327 | 시간 111[s] | 퍼플렉서티 326.58\n",
      "| 에폭 1 |  반복 461 / 1327 | 시간 116[s] | 퍼플렉서티 327.58\n",
      "| 에폭 1 |  반복 481 / 1327 | 시간 121[s] | 퍼플렉서티 309.77\n",
      "| 에폭 1 |  반복 501 / 1327 | 시간 126[s] | 퍼플렉서티 319.16\n",
      "| 에폭 1 |  반복 521 / 1327 | 시간 131[s] | 퍼플렉서티 304.30\n",
      "| 에폭 1 |  반복 541 / 1327 | 시간 136[s] | 퍼플렉서티 320.87\n",
      "| 에폭 1 |  반복 561 / 1327 | 시간 141[s] | 퍼플렉서티 286.99\n",
      "| 에폭 1 |  반복 581 / 1327 | 시간 146[s] | 퍼플렉서티 259.38\n",
      "| 에폭 1 |  반복 601 / 1327 | 시간 151[s] | 퍼플렉서티 340.91\n",
      "| 에폭 1 |  반복 621 / 1327 | 시간 156[s] | 퍼플렉서티 311.85\n",
      "| 에폭 1 |  반복 641 / 1327 | 시간 161[s] | 퍼플렉서티 283.64\n",
      "| 에폭 1 |  반복 661 / 1327 | 시간 166[s] | 퍼플렉서티 272.22\n",
      "| 에폭 1 |  반복 681 / 1327 | 시간 171[s] | 퍼플렉서티 230.33\n",
      "| 에폭 1 |  반복 701 / 1327 | 시간 176[s] | 퍼플렉서티 252.43\n",
      "| 에폭 1 |  반복 721 / 1327 | 시간 181[s] | 퍼플렉서티 260.79\n",
      "| 에폭 1 |  반복 741 / 1327 | 시간 186[s] | 퍼플렉서티 223.89\n",
      "| 에폭 1 |  반복 761 / 1327 | 시간 191[s] | 퍼플렉서티 238.62\n",
      "| 에폭 1 |  반복 781 / 1327 | 시간 196[s] | 퍼플렉서티 219.71\n",
      "| 에폭 1 |  반복 801 / 1327 | 시간 201[s] | 퍼플렉서티 245.03\n",
      "| 에폭 1 |  반복 821 / 1327 | 시간 206[s] | 퍼플렉서티 227.64\n",
      "| 에폭 1 |  반복 841 / 1327 | 시간 211[s] | 퍼플렉서티 230.74\n",
      "| 에폭 1 |  반복 861 / 1327 | 시간 216[s] | 퍼플렉서티 224.31\n",
      "| 에폭 1 |  반복 881 / 1327 | 시간 221[s] | 퍼플렉서티 205.52\n",
      "| 에폭 1 |  반복 901 / 1327 | 시간 226[s] | 퍼플렉서티 257.06\n",
      "| 에폭 1 |  반복 921 / 1327 | 시간 231[s] | 퍼플렉서티 226.96\n",
      "| 에폭 1 |  반복 941 / 1327 | 시간 236[s] | 퍼플렉서티 232.04\n",
      "| 에폭 1 |  반복 961 / 1327 | 시간 241[s] | 퍼플렉서티 245.23\n",
      "| 에폭 1 |  반복 981 / 1327 | 시간 246[s] | 퍼플렉서티 229.96\n",
      "| 에폭 1 |  반복 1001 / 1327 | 시간 251[s] | 퍼플렉서티 193.19\n",
      "| 에폭 1 |  반복 1021 / 1327 | 시간 256[s] | 퍼플렉서티 226.43\n",
      "| 에폭 1 |  반복 1041 / 1327 | 시간 261[s] | 퍼플렉서티 210.04\n",
      "| 에폭 1 |  반복 1061 / 1327 | 시간 266[s] | 퍼플렉서티 199.99\n",
      "| 에폭 1 |  반복 1081 / 1327 | 시간 271[s] | 퍼플렉서티 170.39\n",
      "| 에폭 1 |  반복 1101 / 1327 | 시간 276[s] | 퍼플렉서티 192.60\n",
      "| 에폭 1 |  반복 1121 / 1327 | 시간 282[s] | 퍼플렉서티 230.78\n",
      "| 에폭 1 |  반복 1141 / 1327 | 시간 287[s] | 퍼플렉서티 210.08\n",
      "| 에폭 1 |  반복 1161 / 1327 | 시간 293[s] | 퍼플렉서티 198.99\n",
      "| 에폭 1 |  반복 1181 / 1327 | 시간 298[s] | 퍼플렉서티 191.53\n",
      "| 에폭 1 |  반복 1201 / 1327 | 시간 302[s] | 퍼플렉서티 164.58\n",
      "| 에폭 1 |  반복 1221 / 1327 | 시간 307[s] | 퍼플렉서티 160.95\n",
      "| 에폭 1 |  반복 1241 / 1327 | 시간 312[s] | 퍼플렉서티 188.30\n",
      "| 에폭 1 |  반복 1261 / 1327 | 시간 317[s] | 퍼플렉서티 172.25\n",
      "| 에폭 1 |  반복 1281 / 1327 | 시간 322[s] | 퍼플렉서티 180.01\n",
      "| 에폭 1 |  반복 1301 / 1327 | 시간 328[s] | 퍼플렉서티 224.50\n",
      "| 에폭 1 |  반복 1321 / 1327 | 시간 333[s] | 퍼플렉서티 211.32\n",
      "| 에폭 2 |  반복 1 / 1327 | 시간 334[s] | 퍼플렉서티 223.06\n",
      "| 에폭 2 |  반복 21 / 1327 | 시간 339[s] | 퍼플렉서티 206.18\n",
      "| 에폭 2 |  반복 41 / 1327 | 시간 344[s] | 퍼플렉서티 191.38\n",
      "| 에폭 2 |  반복 61 / 1327 | 시간 349[s] | 퍼플렉서티 180.46\n",
      "| 에폭 2 |  반복 81 / 1327 | 시간 354[s] | 퍼플렉서티 160.30\n",
      "| 에폭 2 |  반복 101 / 1327 | 시간 359[s] | 퍼플렉서티 153.55\n",
      "| 에폭 2 |  반복 121 / 1327 | 시간 364[s] | 퍼플렉서티 162.00\n",
      "| 에폭 2 |  반복 141 / 1327 | 시간 369[s] | 퍼플렉서티 179.30\n",
      "| 에폭 2 |  반복 161 / 1327 | 시간 374[s] | 퍼플렉서티 193.04\n",
      "| 에폭 2 |  반복 181 / 1327 | 시간 379[s] | 퍼플렉서티 202.78\n",
      "| 에폭 2 |  반복 201 / 1327 | 시간 384[s] | 퍼플렉서티 186.87\n",
      "| 에폭 2 |  반복 221 / 1327 | 시간 389[s] | 퍼플렉서티 184.70\n",
      "| 에폭 2 |  반복 241 / 1327 | 시간 394[s] | 퍼플렉서티 176.54\n",
      "| 에폭 2 |  반복 261 / 1327 | 시간 399[s] | 퍼플렉서티 187.85\n",
      "| 에폭 2 |  반복 281 / 1327 | 시간 404[s] | 퍼플렉서티 187.00\n",
      "| 에폭 2 |  반복 301 / 1327 | 시간 409[s] | 퍼플렉서티 167.98\n",
      "| 에폭 2 |  반복 321 / 1327 | 시간 414[s] | 퍼플렉서티 139.84\n",
      "| 에폭 2 |  반복 341 / 1327 | 시간 419[s] | 퍼플렉서티 172.52\n",
      "| 에폭 2 |  반복 361 / 1327 | 시간 424[s] | 퍼플렉서티 199.11\n",
      "| 에폭 2 |  반복 381 / 1327 | 시간 429[s] | 퍼플렉서티 156.13\n",
      "| 에폭 2 |  반복 401 / 1327 | 시간 434[s] | 퍼플렉서티 168.93\n",
      "| 에폭 2 |  반복 421 / 1327 | 시간 439[s] | 퍼플렉서티 155.91\n",
      "| 에폭 2 |  반복 441 / 1327 | 시간 444[s] | 퍼플렉서티 166.01\n",
      "| 에폭 2 |  반복 461 / 1327 | 시간 449[s] | 퍼플렉서티 159.85\n",
      "| 에폭 2 |  반복 481 / 1327 | 시간 454[s] | 퍼플렉서티 157.95\n",
      "| 에폭 2 |  반복 501 / 1327 | 시간 459[s] | 퍼플렉서티 172.37\n",
      "| 에폭 2 |  반복 521 / 1327 | 시간 464[s] | 퍼플렉서티 174.31\n",
      "| 에폭 2 |  반복 541 / 1327 | 시간 469[s] | 퍼플렉서티 178.17\n",
      "| 에폭 2 |  반복 561 / 1327 | 시간 474[s] | 퍼플렉서티 157.01\n",
      "| 에폭 2 |  반복 581 / 1327 | 시간 479[s] | 퍼플렉서티 140.94\n",
      "| 에폭 2 |  반복 601 / 1327 | 시간 484[s] | 퍼플렉서티 192.87\n",
      "| 에폭 2 |  반복 621 / 1327 | 시간 489[s] | 퍼플렉서티 184.83\n",
      "| 에폭 2 |  반복 641 / 1327 | 시간 494[s] | 퍼플렉서티 167.80\n",
      "| 에폭 2 |  반복 661 / 1327 | 시간 499[s] | 퍼플렉서티 157.76\n",
      "| 에폭 2 |  반복 681 / 1327 | 시간 504[s] | 퍼플렉서티 131.34\n",
      "| 에폭 2 |  반복 701 / 1327 | 시간 510[s] | 퍼플렉서티 153.39\n",
      "| 에폭 2 |  반복 721 / 1327 | 시간 515[s] | 퍼플렉서티 162.64\n",
      "| 에폭 2 |  반복 741 / 1327 | 시간 520[s] | 퍼플렉서티 136.34\n",
      "| 에폭 2 |  반복 761 / 1327 | 시간 525[s] | 퍼플렉서티 134.12\n",
      "| 에폭 2 |  반복 781 / 1327 | 시간 530[s] | 퍼플렉서티 136.64\n",
      "| 에폭 2 |  반복 801 / 1327 | 시간 535[s] | 퍼플렉서티 149.06\n",
      "| 에폭 2 |  반복 821 / 1327 | 시간 539[s] | 퍼플렉서티 144.81\n",
      "| 에폭 2 |  반복 841 / 1327 | 시간 544[s] | 퍼플렉서티 147.14\n",
      "| 에폭 2 |  반복 861 / 1327 | 시간 549[s] | 퍼플렉서티 147.30\n",
      "| 에폭 2 |  반복 881 / 1327 | 시간 554[s] | 퍼플렉서티 130.89\n",
      "| 에폭 2 |  반복 901 / 1327 | 시간 559[s] | 퍼플렉서티 168.23\n",
      "| 에폭 2 |  반복 921 / 1327 | 시간 564[s] | 퍼플렉서티 146.64\n",
      "| 에폭 2 |  반복 941 / 1327 | 시간 569[s] | 퍼플렉서티 155.72\n",
      "| 에폭 2 |  반복 961 / 1327 | 시간 574[s] | 퍼플렉서티 165.40\n",
      "| 에폭 2 |  반복 981 / 1327 | 시간 579[s] | 퍼플렉서티 154.75\n",
      "| 에폭 2 |  반복 1001 / 1327 | 시간 584[s] | 퍼플렉서티 132.78\n",
      "| 에폭 2 |  반복 1021 / 1327 | 시간 589[s] | 퍼플렉서티 158.01\n",
      "| 에폭 2 |  반복 1041 / 1327 | 시간 595[s] | 퍼플렉서티 145.06\n",
      "| 에폭 2 |  반복 1061 / 1327 | 시간 600[s] | 퍼플렉서티 129.75\n",
      "| 에폭 2 |  반복 1081 / 1327 | 시간 605[s] | 퍼플렉서티 112.08\n",
      "| 에폭 2 |  반복 1101 / 1327 | 시간 609[s] | 퍼플렉서티 121.37\n",
      "| 에폭 2 |  반복 1121 / 1327 | 시간 615[s] | 퍼플렉서티 155.79\n",
      "| 에폭 2 |  반복 1141 / 1327 | 시간 620[s] | 퍼플렉서티 143.67\n",
      "| 에폭 2 |  반복 1161 / 1327 | 시간 625[s] | 퍼플렉서티 133.29\n",
      "| 에폭 2 |  반복 1181 / 1327 | 시간 631[s] | 퍼플렉서티 135.57\n",
      "| 에폭 2 |  반복 1201 / 1327 | 시간 636[s] | 퍼플렉서티 113.00\n",
      "| 에폭 2 |  반복 1221 / 1327 | 시간 641[s] | 퍼플렉서티 110.92\n",
      "| 에폭 2 |  반복 1241 / 1327 | 시간 646[s] | 퍼플렉서티 130.95\n",
      "| 에폭 2 |  반복 1261 / 1327 | 시간 652[s] | 퍼플렉서티 125.00\n",
      "| 에폭 2 |  반복 1281 / 1327 | 시간 657[s] | 퍼플렉서티 125.19\n",
      "| 에폭 2 |  반복 1301 / 1327 | 시간 662[s] | 퍼플렉서티 159.03\n",
      "| 에폭 2 |  반복 1321 / 1327 | 시간 667[s] | 퍼플렉서티 154.43\n",
      "| 에폭 3 |  반복 1 / 1327 | 시간 669[s] | 퍼플렉서티 162.56\n",
      "| 에폭 3 |  반복 21 / 1327 | 시간 674[s] | 퍼플렉서티 144.73\n",
      "| 에폭 3 |  반복 41 / 1327 | 시간 679[s] | 퍼플렉서티 135.74\n",
      "| 에폭 3 |  반복 61 / 1327 | 시간 684[s] | 퍼플렉서티 129.47\n",
      "| 에폭 3 |  반복 81 / 1327 | 시간 689[s] | 퍼플렉서티 119.13\n",
      "| 에폭 3 |  반복 101 / 1327 | 시간 694[s] | 퍼플렉서티 106.10\n",
      "| 에폭 3 |  반복 121 / 1327 | 시간 699[s] | 퍼플렉서티 117.15\n",
      "| 에폭 3 |  반복 141 / 1327 | 시간 704[s] | 퍼플렉서티 127.01\n",
      "| 에폭 3 |  반복 161 / 1327 | 시간 709[s] | 퍼플렉서티 142.30\n",
      "| 에폭 3 |  반복 181 / 1327 | 시간 715[s] | 퍼플렉서티 151.65\n",
      "| 에폭 3 |  반복 201 / 1327 | 시간 720[s] | 퍼플렉서티 142.55\n",
      "| 에폭 3 |  반복 221 / 1327 | 시간 725[s] | 퍼플렉서티 141.88\n",
      "| 에폭 3 |  반복 241 / 1327 | 시간 731[s] | 퍼플렉서티 134.66\n",
      "| 에폭 3 |  반복 261 / 1327 | 시간 736[s] | 퍼플렉서티 139.92\n",
      "| 에폭 3 |  반복 281 / 1327 | 시간 741[s] | 퍼플렉서티 142.88\n",
      "| 에폭 3 |  반복 301 / 1327 | 시간 746[s] | 퍼플렉서티 125.44\n",
      "| 에폭 3 |  반복 321 / 1327 | 시간 752[s] | 퍼플렉서티 103.08\n",
      "| 에폭 3 |  반복 341 / 1327 | 시간 757[s] | 퍼플렉서티 124.78\n",
      "| 에폭 3 |  반복 361 / 1327 | 시간 762[s] | 퍼플렉서티 153.26\n",
      "| 에폭 3 |  반복 381 / 1327 | 시간 767[s] | 퍼플렉서티 115.65\n",
      "| 에폭 3 |  반복 401 / 1327 | 시간 772[s] | 퍼플렉서티 130.10\n",
      "| 에폭 3 |  반복 421 / 1327 | 시간 777[s] | 퍼플렉서티 114.12\n",
      "| 에폭 3 |  반복 441 / 1327 | 시간 782[s] | 퍼플렉서티 126.03\n",
      "| 에폭 3 |  반복 461 / 1327 | 시간 787[s] | 퍼플렉서티 119.89\n",
      "| 에폭 3 |  반복 481 / 1327 | 시간 793[s] | 퍼플렉서티 120.20\n",
      "| 에폭 3 |  반복 501 / 1327 | 시간 798[s] | 퍼플렉서티 129.35\n",
      "| 에폭 3 |  반복 521 / 1327 | 시간 803[s] | 퍼플렉서티 139.39\n",
      "| 에폭 3 |  반복 541 / 1327 | 시간 808[s] | 퍼플렉서티 137.71\n",
      "| 에폭 3 |  반복 561 / 1327 | 시간 814[s] | 퍼플렉서티 120.11\n",
      "| 에폭 3 |  반복 581 / 1327 | 시간 819[s] | 퍼플렉서티 108.36\n",
      "| 에폭 3 |  반복 601 / 1327 | 시간 824[s] | 퍼플렉서티 149.84\n",
      "| 에폭 3 |  반복 621 / 1327 | 시간 829[s] | 퍼플렉서티 143.61\n",
      "| 에폭 3 |  반복 641 / 1327 | 시간 834[s] | 퍼플렉서티 129.57\n",
      "| 에폭 3 |  반복 661 / 1327 | 시간 839[s] | 퍼플렉서티 121.05\n",
      "| 에폭 3 |  반복 681 / 1327 | 시간 845[s] | 퍼플렉서티 101.14\n",
      "| 에폭 3 |  반복 701 / 1327 | 시간 850[s] | 퍼플렉서티 120.20\n",
      "| 에폭 3 |  반복 721 / 1327 | 시간 856[s] | 퍼플렉서티 127.38\n",
      "| 에폭 3 |  반복 741 / 1327 | 시간 861[s] | 퍼플렉서티 109.23\n",
      "| 에폭 3 |  반복 761 / 1327 | 시간 866[s] | 퍼플렉서티 103.97\n",
      "| 에폭 3 |  반복 781 / 1327 | 시간 872[s] | 퍼플렉서티 104.96\n",
      "| 에폭 3 |  반복 801 / 1327 | 시간 877[s] | 퍼플렉서티 116.48\n",
      "| 에폭 3 |  반복 821 / 1327 | 시간 882[s] | 퍼플렉서티 116.76\n",
      "| 에폭 3 |  반복 841 / 1327 | 시간 887[s] | 퍼플렉서티 115.15\n",
      "| 에폭 3 |  반복 861 / 1327 | 시간 893[s] | 퍼플렉서티 120.65\n",
      "| 에폭 3 |  반복 881 / 1327 | 시간 898[s] | 퍼플렉서티 107.14\n",
      "| 에폭 3 |  반복 901 / 1327 | 시간 903[s] | 퍼플렉서티 133.44\n",
      "| 에폭 3 |  반복 921 / 1327 | 시간 909[s] | 퍼플렉서티 118.58\n",
      "| 에폭 3 |  반복 941 / 1327 | 시간 914[s] | 퍼플렉서티 128.32\n",
      "| 에폭 3 |  반복 961 / 1327 | 시간 919[s] | 퍼플렉서티 132.12\n",
      "| 에폭 3 |  반복 981 / 1327 | 시간 925[s] | 퍼플렉서티 124.38\n",
      "| 에폭 3 |  반복 1001 / 1327 | 시간 930[s] | 퍼플렉서티 109.01\n",
      "| 에폭 3 |  반복 1021 / 1327 | 시간 936[s] | 퍼플렉서티 128.70\n",
      "| 에폭 3 |  반복 1041 / 1327 | 시간 941[s] | 퍼플렉서티 121.06\n",
      "| 에폭 3 |  반복 1061 / 1327 | 시간 947[s] | 퍼플렉서티 102.38\n",
      "| 에폭 3 |  반복 1081 / 1327 | 시간 952[s] | 퍼플렉서티 89.06\n",
      "| 에폭 3 |  반복 1101 / 1327 | 시간 958[s] | 퍼플렉서티 95.92\n",
      "| 에폭 3 |  반복 1121 / 1327 | 시간 963[s] | 퍼플렉서티 123.47\n",
      "| 에폭 3 |  반복 1141 / 1327 | 시간 968[s] | 퍼플렉서티 115.85\n",
      "| 에폭 3 |  반복 1161 / 1327 | 시간 973[s] | 퍼플렉서티 107.04\n",
      "| 에폭 3 |  반복 1181 / 1327 | 시간 978[s] | 퍼플렉서티 111.24\n",
      "| 에폭 3 |  반복 1201 / 1327 | 시간 983[s] | 퍼플렉서티 94.66\n",
      "| 에폭 3 |  반복 1221 / 1327 | 시간 989[s] | 퍼플렉서티 89.51\n",
      "| 에폭 3 |  반복 1241 / 1327 | 시간 994[s] | 퍼플렉서티 107.15\n",
      "| 에폭 3 |  반복 1261 / 1327 | 시간 999[s] | 퍼플렉서티 105.55\n",
      "| 에폭 3 |  반복 1281 / 1327 | 시간 1004[s] | 퍼플렉서티 102.27\n",
      "| 에폭 3 |  반복 1301 / 1327 | 시간 1009[s] | 퍼플렉서티 130.01\n",
      "| 에폭 3 |  반복 1321 / 1327 | 시간 1014[s] | 퍼플렉서티 127.63\n",
      "| 에폭 4 |  반복 1 / 1327 | 시간 1016[s] | 퍼플렉서티 134.64\n",
      "| 에폭 4 |  반복 21 / 1327 | 시간 1022[s] | 퍼플렉서티 122.43\n",
      "| 에폭 4 |  반복 41 / 1327 | 시간 1027[s] | 퍼플렉서티 107.55\n",
      "| 에폭 4 |  반복 61 / 1327 | 시간 1032[s] | 퍼플렉서티 108.63\n",
      "| 에폭 4 |  반복 81 / 1327 | 시간 1038[s] | 퍼플렉서티 96.89\n",
      "| 에폭 4 |  반복 101 / 1327 | 시간 1044[s] | 퍼플렉서티 87.08\n",
      "| 에폭 4 |  반복 121 / 1327 | 시간 1050[s] | 퍼플렉서티 96.41\n",
      "| 에폭 4 |  반복 141 / 1327 | 시간 1055[s] | 퍼플렉서티 104.06\n",
      "| 에폭 4 |  반복 161 / 1327 | 시간 1061[s] | 퍼플렉서티 117.67\n",
      "| 에폭 4 |  반복 181 / 1327 | 시간 1066[s] | 퍼플렉서티 128.95\n",
      "| 에폭 4 |  반복 201 / 1327 | 시간 1072[s] | 퍼플렉서티 121.14\n",
      "| 에폭 4 |  반복 221 / 1327 | 시간 1077[s] | 퍼플렉서티 122.84\n",
      "| 에폭 4 |  반복 241 / 1327 | 시간 1083[s] | 퍼플렉서티 114.64\n",
      "| 에폭 4 |  반복 261 / 1327 | 시간 1088[s] | 퍼플렉서티 114.33\n",
      "| 에폭 4 |  반복 281 / 1327 | 시간 1093[s] | 퍼플렉서티 121.27\n",
      "| 에폭 4 |  반복 301 / 1327 | 시간 1099[s] | 퍼플렉서티 103.95\n",
      "| 에폭 4 |  반복 321 / 1327 | 시간 1104[s] | 퍼플렉서티 84.49\n",
      "| 에폭 4 |  반복 341 / 1327 | 시간 1110[s] | 퍼플렉서티 101.67\n",
      "| 에폭 4 |  반복 361 / 1327 | 시간 1115[s] | 퍼플렉서티 128.38\n",
      "| 에폭 4 |  반복 381 / 1327 | 시간 1120[s] | 퍼플렉서티 98.72\n",
      "| 에폭 4 |  반복 401 / 1327 | 시간 1126[s] | 퍼플렉서티 110.08\n",
      "| 에폭 4 |  반복 421 / 1327 | 시간 1132[s] | 퍼플렉서티 95.15\n",
      "| 에폭 4 |  반복 441 / 1327 | 시간 1137[s] | 퍼플렉서티 105.06\n",
      "| 에폭 4 |  반복 461 / 1327 | 시간 1142[s] | 퍼플렉서티 101.22\n",
      "| 에폭 4 |  반복 481 / 1327 | 시간 1147[s] | 퍼플렉서티 103.35\n",
      "| 에폭 4 |  반복 501 / 1327 | 시간 1153[s] | 퍼플렉서티 109.19\n",
      "| 에폭 4 |  반복 521 / 1327 | 시간 1158[s] | 퍼플렉서티 118.21\n",
      "| 에폭 4 |  반복 541 / 1327 | 시간 1163[s] | 퍼플렉서티 113.22\n",
      "| 에폭 4 |  반복 561 / 1327 | 시간 1168[s] | 퍼플렉서티 104.25\n",
      "| 에폭 4 |  반복 581 / 1327 | 시간 1173[s] | 퍼플렉서티 91.05\n",
      "| 에폭 4 |  반복 601 / 1327 | 시간 1178[s] | 퍼플렉서티 128.09\n",
      "| 에폭 4 |  반복 621 / 1327 | 시간 1184[s] | 퍼플렉서티 122.63\n",
      "| 에폭 4 |  반복 641 / 1327 | 시간 1189[s] | 퍼플렉서티 110.80\n",
      "| 에폭 4 |  반복 661 / 1327 | 시간 1194[s] | 퍼플렉서티 103.61\n",
      "| 에폭 4 |  반복 681 / 1327 | 시간 1199[s] | 퍼플렉서티 85.78\n",
      "| 에폭 4 |  반복 701 / 1327 | 시간 1205[s] | 퍼플렉서티 103.00\n",
      "| 에폭 4 |  반복 721 / 1327 | 시간 1211[s] | 퍼플렉서티 107.99\n",
      "| 에폭 4 |  반복 741 / 1327 | 시간 1217[s] | 퍼플렉서티 96.41\n",
      "| 에폭 4 |  반복 761 / 1327 | 시간 1222[s] | 퍼플렉서티 89.21\n",
      "| 에폭 4 |  반복 781 / 1327 | 시간 1227[s] | 퍼플렉서티 88.26\n",
      "| 에폭 4 |  반복 801 / 1327 | 시간 1232[s] | 퍼플렉서티 99.68\n",
      "| 에폭 4 |  반복 821 / 1327 | 시간 1238[s] | 퍼플렉서티 101.96\n",
      "| 에폭 4 |  반복 841 / 1327 | 시간 1243[s] | 퍼플렉서티 99.08\n",
      "| 에폭 4 |  반복 861 / 1327 | 시간 1248[s] | 퍼플렉서티 103.54\n",
      "| 에폭 4 |  반복 881 / 1327 | 시간 1253[s] | 퍼플렉서티 92.08\n",
      "| 에폭 4 |  반복 901 / 1327 | 시간 1259[s] | 퍼플렉서티 115.97\n",
      "| 에폭 4 |  반복 921 / 1327 | 시간 1264[s] | 퍼플렉서티 102.67\n",
      "| 에폭 4 |  반복 941 / 1327 | 시간 1269[s] | 퍼플렉서티 113.18\n",
      "| 에폭 4 |  반복 961 / 1327 | 시간 1274[s] | 퍼플렉서티 112.48\n",
      "| 에폭 4 |  반복 981 / 1327 | 시간 1280[s] | 퍼플렉서티 107.60\n",
      "| 에폭 4 |  반복 1001 / 1327 | 시간 1285[s] | 퍼플렉서티 96.86\n",
      "| 에폭 4 |  반복 1021 / 1327 | 시간 1290[s] | 퍼플렉서티 112.61\n",
      "| 에폭 4 |  반복 1041 / 1327 | 시간 1295[s] | 퍼플렉서티 105.97\n",
      "| 에폭 4 |  반복 1061 / 1327 | 시간 1300[s] | 퍼플렉서티 88.65\n",
      "| 에폭 4 |  반복 1081 / 1327 | 시간 1305[s] | 퍼플렉서티 78.49\n",
      "| 에폭 4 |  반복 1101 / 1327 | 시간 1310[s] | 퍼플렉서티 79.45\n",
      "| 에폭 4 |  반복 1121 / 1327 | 시간 1315[s] | 퍼플렉서티 104.62\n",
      "| 에폭 4 |  반복 1141 / 1327 | 시간 1320[s] | 퍼플렉서티 100.77\n",
      "| 에폭 4 |  반복 1161 / 1327 | 시간 1325[s] | 퍼플렉서티 90.91\n",
      "| 에폭 4 |  반복 1181 / 1327 | 시간 1330[s] | 퍼플렉서티 96.45\n",
      "| 에폭 4 |  반복 1201 / 1327 | 시간 1336[s] | 퍼플렉서티 84.32\n",
      "| 에폭 4 |  반복 1221 / 1327 | 시간 1341[s] | 퍼플렉서티 76.70\n",
      "| 에폭 4 |  반복 1241 / 1327 | 시간 1346[s] | 퍼플렉서티 92.74\n",
      "| 에폭 4 |  반복 1261 / 1327 | 시간 1351[s] | 퍼플렉서티 94.39\n",
      "| 에폭 4 |  반복 1281 / 1327 | 시간 1356[s] | 퍼플렉서티 89.64\n",
      "| 에폭 4 |  반복 1301 / 1327 | 시간 1361[s] | 퍼플렉서티 111.76\n",
      "| 에폭 4 |  반복 1321 / 1327 | 시간 1366[s] | 퍼플렉서티 111.92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "퍼플렉서티 평가 중 ...\n",
      "234 / 235\n",
      "테스트 퍼플렉서티:  134.6032180000685\n"
     ]
    }
   ],
   "source": [
    "# chap06/train_rnnlm.py\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "from rnnlm import Rnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 35     # RNN을 펼치는 크기\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# 모델 생성\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "# 기울기 클리핑을 적용하여 학습\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad,\n",
    "            eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)\n",
    "\n",
    "# 매개변수 저장\n",
    "model.save_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 RNNLM 추가 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1 LSTM 계층 다층화\n",
    "\n",
    "- 첫 번째 LSTM 레이어의 hidden state $\\mathbf{h}_{t}$가 두 번째 LSTM 레이어의 입력으로 들어간다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_6-29.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2 드롭아웃에 의한 과적합 억제\n",
    "\n",
    "- 일반적으로 RNN이 단순한 NN보다 쉽게 과적합(overfitting)을 일으킨다.\n",
    "\n",
    "- 과적합을 억제하는 전통적인 방법은 다음과 같다.\n",
    "    - 훈련 데이터의 양 늘리기\n",
    "    - 모델의 복잡도 줄이기\n",
    "    \n",
    "    \n",
    "- RNN계열에서의 드롭아웃(dropout)은 아래의 그림과 같이 **변형 드롭아웃**(Variational Dropout)을 사용한다.\n",
    "\n",
    "- RNN에서의 드롭아웃은 같은 계층에 속한 드롭아웃들은 같은 마스크(mask)를 공유한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_6-34.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.3 가중치 공유(weight tying)\n",
    "\n",
    "<img src=\"./images/fig_6-35.png\" height=\"60%\" width=\"60%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 10000.21\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 3[s] | 퍼플렉서티 3270.81\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 7[s] | 퍼플렉서티 1745.75\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 10[s] | 퍼플렉서티 1292.69\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 13[s] | 퍼플렉서티 1063.62\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 16[s] | 퍼플렉서티 837.68\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 20[s] | 퍼플렉서티 805.60\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 23[s] | 퍼플렉서티 722.00\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 26[s] | 퍼플렉서티 685.79\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 29[s] | 퍼플렉서티 689.02\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 33[s] | 퍼플렉서티 588.95\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 36[s] | 퍼플렉서티 574.83\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 39[s] | 퍼플렉서티 525.74\n",
      "| 에폭 1 |  반복 261 / 1327 | 시간 42[s] | 퍼플렉서티 536.65\n",
      "| 에폭 1 |  반복 281 / 1327 | 시간 45[s] | 퍼플렉서티 516.62\n",
      "| 에폭 1 |  반복 301 / 1327 | 시간 48[s] | 퍼플렉서티 447.58\n",
      "| 에폭 1 |  반복 321 / 1327 | 시간 51[s] | 퍼플렉서티 397.04\n",
      "| 에폭 1 |  반복 341 / 1327 | 시간 54[s] | 퍼플렉서티 456.86\n",
      "| 에폭 1 |  반복 361 / 1327 | 시간 57[s] | 퍼플렉서티 469.31\n",
      "| 에폭 1 |  반복 381 / 1327 | 시간 61[s] | 퍼플렉서티 384.75\n",
      "| 에폭 1 |  반복 401 / 1327 | 시간 64[s] | 퍼플렉서티 402.99\n",
      "| 에폭 1 |  반복 421 / 1327 | 시간 67[s] | 퍼플렉서티 402.26\n",
      "| 에폭 1 |  반복 441 / 1327 | 시간 70[s] | 퍼플렉서티 377.78\n",
      "| 에폭 1 |  반복 461 / 1327 | 시간 73[s] | 퍼플렉서티 371.25\n",
      "| 에폭 1 |  반복 481 / 1327 | 시간 76[s] | 퍼플렉서티 349.29\n",
      "| 에폭 1 |  반복 501 / 1327 | 시간 79[s] | 퍼플렉서티 351.78\n",
      "| 에폭 1 |  반복 521 / 1327 | 시간 83[s] | 퍼플렉서티 341.22\n",
      "| 에폭 1 |  반복 541 / 1327 | 시간 86[s] | 퍼플렉서티 360.36\n",
      "| 에폭 1 |  반복 561 / 1327 | 시간 90[s] | 퍼플렉서티 319.07\n",
      "| 에폭 1 |  반복 581 / 1327 | 시간 93[s] | 퍼플렉서티 291.91\n",
      "| 에폭 1 |  반복 601 / 1327 | 시간 96[s] | 퍼플렉서티 378.19\n",
      "| 에폭 1 |  반복 621 / 1327 | 시간 100[s] | 퍼플렉서티 343.54\n",
      "| 에폭 1 |  반복 641 / 1327 | 시간 103[s] | 퍼플렉서티 314.25\n",
      "| 에폭 1 |  반복 661 / 1327 | 시간 106[s] | 퍼플렉서티 298.70\n",
      "| 에폭 1 |  반복 681 / 1327 | 시간 110[s] | 퍼플렉서티 257.36\n",
      "| 에폭 1 |  반복 701 / 1327 | 시간 113[s] | 퍼플렉서티 280.15\n",
      "| 에폭 1 |  반복 721 / 1327 | 시간 117[s] | 퍼플렉서티 286.61\n",
      "| 에폭 1 |  반복 741 / 1327 | 시간 121[s] | 퍼플렉서티 246.22\n",
      "| 에폭 1 |  반복 761 / 1327 | 시간 124[s] | 퍼플렉서티 261.20\n",
      "| 에폭 1 |  반복 781 / 1327 | 시간 127[s] | 퍼플렉서티 242.73\n",
      "| 에폭 1 |  반복 801 / 1327 | 시간 130[s] | 퍼플렉서티 268.34\n",
      "| 에폭 1 |  반복 821 / 1327 | 시간 134[s] | 퍼플렉서티 251.47\n",
      "| 에폭 1 |  반복 841 / 1327 | 시간 137[s] | 퍼플렉서티 256.63\n",
      "| 에폭 1 |  반복 861 / 1327 | 시간 140[s] | 퍼플렉서티 249.94\n",
      "| 에폭 1 |  반복 881 / 1327 | 시간 143[s] | 퍼플렉서티 231.84\n",
      "| 에폭 1 |  반복 901 / 1327 | 시간 146[s] | 퍼플렉서티 281.78\n",
      "| 에폭 1 |  반복 921 / 1327 | 시간 150[s] | 퍼플렉서티 256.16\n",
      "| 에폭 1 |  반복 941 / 1327 | 시간 153[s] | 퍼플렉서티 255.27\n",
      "| 에폭 1 |  반복 961 / 1327 | 시간 156[s] | 퍼플렉서티 273.87\n",
      "| 에폭 1 |  반복 981 / 1327 | 시간 159[s] | 퍼플렉서티 256.84\n",
      "| 에폭 1 |  반복 1001 / 1327 | 시간 162[s] | 퍼플렉서티 217.52\n",
      "| 에폭 1 |  반복 1021 / 1327 | 시간 166[s] | 퍼플렉서티 253.38\n",
      "| 에폭 1 |  반복 1041 / 1327 | 시간 169[s] | 퍼플렉서티 231.26\n",
      "| 에폭 1 |  반복 1061 / 1327 | 시간 172[s] | 퍼플렉서티 217.75\n",
      "| 에폭 1 |  반복 1081 / 1327 | 시간 176[s] | 퍼플렉서티 188.30\n",
      "| 에폭 1 |  반복 1101 / 1327 | 시간 179[s] | 퍼플렉서티 215.32\n",
      "| 에폭 1 |  반복 1121 / 1327 | 시간 182[s] | 퍼플렉서티 255.38\n",
      "| 에폭 1 |  반복 1141 / 1327 | 시간 185[s] | 퍼플렉서티 230.92\n",
      "| 에폭 1 |  반복 1161 / 1327 | 시간 188[s] | 퍼플렉서티 220.53\n",
      "| 에폭 1 |  반복 1181 / 1327 | 시간 192[s] | 퍼플렉서티 211.09\n",
      "| 에폭 1 |  반복 1201 / 1327 | 시간 195[s] | 퍼플렉서티 181.68\n",
      "| 에폭 1 |  반복 1221 / 1327 | 시간 198[s] | 퍼플렉서티 176.91\n",
      "| 에폭 1 |  반복 1241 / 1327 | 시간 202[s] | 퍼플렉서티 211.03\n",
      "| 에폭 1 |  반복 1261 / 1327 | 시간 205[s] | 퍼플렉서티 189.68\n",
      "| 에폭 1 |  반복 1281 / 1327 | 시간 208[s] | 퍼플렉서티 197.39\n",
      "| 에폭 1 |  반복 1301 / 1327 | 시간 212[s] | 퍼플렉서티 249.55\n",
      "| 에폭 1 |  반복 1321 / 1327 | 시간 215[s] | 퍼플렉서티 233.45\n",
      "퍼플렉서티 평가 중 ...\n",
      "209 / 210\n",
      "검증 퍼플렉서티:  202.45773\n",
      "--------------------------------------------------\n",
      "| 에폭 2 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 286.60\n",
      "| 에폭 2 |  반복 21 / 1327 | 시간 3[s] | 퍼플렉서티 232.19\n",
      "| 에폭 2 |  반복 41 / 1327 | 시간 6[s] | 퍼플렉서티 214.15\n",
      "| 에폭 2 |  반복 61 / 1327 | 시간 10[s] | 퍼플렉서티 198.14\n",
      "| 에폭 2 |  반복 81 / 1327 | 시간 14[s] | 퍼플렉서티 180.03\n",
      "| 에폭 2 |  반복 101 / 1327 | 시간 17[s] | 퍼플렉서티 170.11\n",
      "| 에폭 2 |  반복 121 / 1327 | 시간 20[s] | 퍼플렉서티 181.94\n",
      "| 에폭 2 |  반복 141 / 1327 | 시간 23[s] | 퍼플렉서티 200.51\n",
      "| 에폭 2 |  반복 161 / 1327 | 시간 26[s] | 퍼플렉서티 217.46\n",
      "| 에폭 2 |  반복 181 / 1327 | 시간 30[s] | 퍼플렉서티 224.33\n",
      "| 에폭 2 |  반복 201 / 1327 | 시간 33[s] | 퍼플렉서티 209.15\n",
      "| 에폭 2 |  반복 221 / 1327 | 시간 36[s] | 퍼플렉서티 205.79\n",
      "| 에폭 2 |  반복 241 / 1327 | 시간 39[s] | 퍼플렉서티 198.09\n",
      "| 에폭 2 |  반복 261 / 1327 | 시간 42[s] | 퍼플렉서티 212.96\n",
      "| 에폭 2 |  반복 281 / 1327 | 시간 45[s] | 퍼플렉서티 206.14\n",
      "| 에폭 2 |  반복 301 / 1327 | 시간 49[s] | 퍼플렉서티 187.09\n",
      "| 에폭 2 |  반복 321 / 1327 | 시간 52[s] | 퍼플렉서티 155.96\n",
      "| 에폭 2 |  반복 341 / 1327 | 시간 55[s] | 퍼플렉서티 201.90\n",
      "| 에폭 2 |  반복 361 / 1327 | 시간 58[s] | 퍼플렉서티 216.97\n",
      "| 에폭 2 |  반복 381 / 1327 | 시간 61[s] | 퍼플렉서티 173.25\n",
      "| 에폭 2 |  반복 401 / 1327 | 시간 64[s] | 퍼플렉서티 195.84\n",
      "| 에폭 2 |  반복 421 / 1327 | 시간 67[s] | 퍼플렉서티 180.08\n",
      "| 에폭 2 |  반복 441 / 1327 | 시간 71[s] | 퍼플렉서티 182.10\n",
      "| 에폭 2 |  반복 461 / 1327 | 시간 74[s] | 퍼플렉서티 183.99\n",
      "| 에폭 2 |  반복 481 / 1327 | 시간 77[s] | 퍼플렉서티 175.79\n",
      "| 에폭 2 |  반복 501 / 1327 | 시간 80[s] | 퍼플렉서티 192.46\n",
      "| 에폭 2 |  반복 521 / 1327 | 시간 83[s] | 퍼플렉서티 191.59\n",
      "| 에폭 2 |  반복 541 / 1327 | 시간 86[s] | 퍼플렉서티 201.94\n",
      "| 에폭 2 |  반복 561 / 1327 | 시간 89[s] | 퍼플렉서티 173.63\n",
      "| 에폭 2 |  반복 581 / 1327 | 시간 93[s] | 퍼플렉서티 159.08\n",
      "| 에폭 2 |  반복 601 / 1327 | 시간 96[s] | 퍼플렉서티 217.61\n",
      "| 에폭 2 |  반복 621 / 1327 | 시간 99[s] | 퍼플렉서티 202.28\n",
      "| 에폭 2 |  반복 641 / 1327 | 시간 102[s] | 퍼플렉서티 183.44\n",
      "| 에폭 2 |  반복 661 / 1327 | 시간 106[s] | 퍼플렉서티 173.68\n",
      "| 에폭 2 |  반복 681 / 1327 | 시간 109[s] | 퍼플렉서티 147.75\n",
      "| 에폭 2 |  반복 701 / 1327 | 시간 112[s] | 퍼플렉서티 169.74\n",
      "| 에폭 2 |  반복 721 / 1327 | 시간 116[s] | 퍼플렉서티 177.47\n",
      "| 에폭 2 |  반복 741 / 1327 | 시간 119[s] | 퍼플렉서티 153.03\n",
      "| 에폭 2 |  반복 761 / 1327 | 시간 122[s] | 퍼플렉서티 152.37\n",
      "| 에폭 2 |  반복 781 / 1327 | 시간 126[s] | 퍼플렉서티 149.54\n",
      "| 에폭 2 |  반복 801 / 1327 | 시간 129[s] | 퍼플렉서티 171.49\n",
      "| 에폭 2 |  반복 821 / 1327 | 시간 132[s] | 퍼플렉서티 164.90\n",
      "| 에폭 2 |  반복 841 / 1327 | 시간 135[s] | 퍼플렉서티 164.92\n",
      "| 에폭 2 |  반복 861 / 1327 | 시간 138[s] | 퍼플렉서티 159.27\n",
      "| 에폭 2 |  반복 881 / 1327 | 시간 142[s] | 퍼플렉서티 148.30\n",
      "| 에폭 2 |  반복 901 / 1327 | 시간 145[s] | 퍼플렉서티 193.08\n",
      "| 에폭 2 |  반복 921 / 1327 | 시간 148[s] | 퍼플렉서티 167.29\n",
      "| 에폭 2 |  반복 941 / 1327 | 시간 151[s] | 퍼플렉서티 169.48\n",
      "| 에폭 2 |  반복 961 / 1327 | 시간 155[s] | 퍼플렉서티 186.09\n",
      "| 에폭 2 |  반복 981 / 1327 | 시간 158[s] | 퍼플렉서티 173.96\n",
      "| 에폭 2 |  반복 1001 / 1327 | 시간 161[s] | 퍼플렉서티 148.36\n",
      "| 에폭 2 |  반복 1021 / 1327 | 시간 164[s] | 퍼플렉서티 174.79\n",
      "| 에폭 2 |  반복 1041 / 1327 | 시간 167[s] | 퍼플렉서티 159.42\n",
      "| 에폭 2 |  반복 1061 / 1327 | 시간 170[s] | 퍼플렉서티 149.30\n",
      "| 에폭 2 |  반복 1081 / 1327 | 시간 173[s] | 퍼플렉서티 124.89\n",
      "| 에폭 2 |  반복 1101 / 1327 | 시간 176[s] | 퍼플렉서티 136.99\n",
      "| 에폭 2 |  반복 1121 / 1327 | 시간 179[s] | 퍼플렉서티 174.07\n",
      "| 에폭 2 |  반복 1141 / 1327 | 시간 182[s] | 퍼플렉서티 164.51\n",
      "| 에폭 2 |  반복 1161 / 1327 | 시간 185[s] | 퍼플렉서티 149.10\n",
      "| 에폭 2 |  반복 1181 / 1327 | 시간 188[s] | 퍼플렉서티 148.98\n",
      "| 에폭 2 |  반복 1201 / 1327 | 시간 192[s] | 퍼플렉서티 126.68\n",
      "| 에폭 2 |  반복 1221 / 1327 | 시간 195[s] | 퍼플렉서티 125.73\n",
      "| 에폭 2 |  반복 1241 / 1327 | 시간 198[s] | 퍼플렉서티 149.12\n",
      "| 에폭 2 |  반복 1261 / 1327 | 시간 201[s] | 퍼플렉서티 139.60\n",
      "| 에폭 2 |  반복 1281 / 1327 | 시간 204[s] | 퍼플렉서티 140.41\n",
      "| 에폭 2 |  반복 1301 / 1327 | 시간 207[s] | 퍼플렉서티 180.31\n",
      "| 에폭 2 |  반복 1321 / 1327 | 시간 210[s] | 퍼플렉서티 173.41\n",
      "퍼플렉서티 평가 중 ...\n",
      "209 / 210\n",
      "검증 퍼플렉서티:  145.84598\n",
      "--------------------------------------------------\n",
      "| 에폭 3 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 227.43\n",
      "| 에폭 3 |  반복 21 / 1327 | 시간 3[s] | 퍼플렉서티 162.21\n",
      "| 에폭 3 |  반복 41 / 1327 | 시간 6[s] | 퍼플렉서티 151.74\n",
      "| 에폭 3 |  반복 61 / 1327 | 시간 9[s] | 퍼플렉서티 143.19\n",
      "| 에폭 3 |  반복 81 / 1327 | 시간 13[s] | 퍼플렉서티 128.26\n",
      "| 에폭 3 |  반복 101 / 1327 | 시간 16[s] | 퍼플렉서티 122.05\n",
      "| 에폭 3 |  반복 121 / 1327 | 시간 19[s] | 퍼플렉서티 132.38\n",
      "| 에폭 3 |  반복 141 / 1327 | 시간 22[s] | 퍼플렉서티 148.00\n",
      "| 에폭 3 |  반복 161 / 1327 | 시간 25[s] | 퍼플렉서티 162.14\n",
      "| 에폭 3 |  반복 181 / 1327 | 시간 28[s] | 퍼플렉서티 168.73\n",
      "| 에폭 3 |  반복 201 / 1327 | 시간 31[s] | 퍼플렉서티 159.22\n",
      "| 에폭 3 |  반복 221 / 1327 | 시간 34[s] | 퍼플렉서티 158.15\n",
      "| 에폭 3 |  반복 241 / 1327 | 시간 37[s] | 퍼플렉서티 151.61\n",
      "| 에폭 3 |  반복 261 / 1327 | 시간 40[s] | 퍼플렉서티 162.29\n",
      "| 에폭 3 |  반복 281 / 1327 | 시간 43[s] | 퍼플렉서티 157.75\n",
      "| 에폭 3 |  반복 301 / 1327 | 시간 46[s] | 퍼플렉서티 140.68\n",
      "| 에폭 3 |  반복 321 / 1327 | 시간 49[s] | 퍼플렉서티 112.61\n",
      "| 에폭 3 |  반복 341 / 1327 | 시간 52[s] | 퍼플렉서티 152.72\n",
      "| 에폭 3 |  반복 361 / 1327 | 시간 56[s] | 퍼플렉서티 165.79\n",
      "| 에폭 3 |  반복 381 / 1327 | 시간 59[s] | 퍼플렉서티 131.18\n",
      "| 에폭 3 |  반복 401 / 1327 | 시간 62[s] | 퍼플렉서티 149.35\n",
      "| 에폭 3 |  반복 421 / 1327 | 시간 65[s] | 퍼플렉서티 132.38\n",
      "| 에폭 3 |  반복 441 / 1327 | 시간 68[s] | 퍼플렉서티 139.66\n",
      "| 에폭 3 |  반복 461 / 1327 | 시간 71[s] | 퍼플렉서티 140.20\n",
      "| 에폭 3 |  반복 481 / 1327 | 시간 74[s] | 퍼플렉서티 136.16\n",
      "| 에폭 3 |  반복 501 / 1327 | 시간 77[s] | 퍼플렉서티 150.68\n",
      "| 에폭 3 |  반복 521 / 1327 | 시간 80[s] | 퍼플렉서티 151.92\n",
      "| 에폭 3 |  반복 541 / 1327 | 시간 83[s] | 퍼플렉서티 158.20\n",
      "| 에폭 3 |  반복 561 / 1327 | 시간 86[s] | 퍼플렉서티 133.30\n",
      "| 에폭 3 |  반복 581 / 1327 | 시간 89[s] | 퍼플렉서티 122.45\n",
      "| 에폭 3 |  반복 601 / 1327 | 시간 93[s] | 퍼플렉서티 169.62\n",
      "| 에폭 3 |  반복 621 / 1327 | 시간 96[s] | 퍼플렉서티 161.72\n",
      "| 에폭 3 |  반복 641 / 1327 | 시간 99[s] | 퍼플렉서티 144.93\n",
      "| 에폭 3 |  반복 661 / 1327 | 시간 102[s] | 퍼플렉서티 135.70\n",
      "| 에폭 3 |  반복 681 / 1327 | 시간 105[s] | 퍼플렉서티 118.75\n",
      "| 에폭 3 |  반복 701 / 1327 | 시간 108[s] | 퍼플렉서티 136.36\n",
      "| 에폭 3 |  반복 721 / 1327 | 시간 111[s] | 퍼플렉서티 141.06\n",
      "| 에폭 3 |  반복 741 / 1327 | 시간 114[s] | 퍼플렉서티 120.17\n",
      "| 에폭 3 |  반복 761 / 1327 | 시간 117[s] | 퍼플렉서티 114.63\n",
      "| 에폭 3 |  반복 781 / 1327 | 시간 120[s] | 퍼플렉서티 119.61\n",
      "| 에폭 3 |  반복 801 / 1327 | 시간 123[s] | 퍼플렉서티 134.67\n",
      "| 에폭 3 |  반복 821 / 1327 | 시간 126[s] | 퍼플렉서티 133.34\n",
      "| 에폭 3 |  반복 841 / 1327 | 시간 129[s] | 퍼플렉서티 133.04\n",
      "| 에폭 3 |  반복 861 / 1327 | 시간 132[s] | 퍼플렉서티 130.18\n",
      "| 에폭 3 |  반복 881 / 1327 | 시간 135[s] | 퍼플렉서티 120.79\n",
      "| 에폭 3 |  반복 901 / 1327 | 시간 138[s] | 퍼플렉서티 155.05\n",
      "| 에폭 3 |  반복 921 / 1327 | 시간 141[s] | 퍼플렉서티 135.19\n",
      "| 에폭 3 |  반복 941 / 1327 | 시간 144[s] | 퍼플렉서티 139.15\n",
      "| 에폭 3 |  반복 961 / 1327 | 시간 147[s] | 퍼플렉서티 153.05\n",
      "| 에폭 3 |  반복 981 / 1327 | 시간 150[s] | 퍼플렉서티 144.38\n",
      "| 에폭 3 |  반복 1001 / 1327 | 시간 153[s] | 퍼플렉서티 123.91\n",
      "| 에폭 3 |  반복 1021 / 1327 | 시간 156[s] | 퍼플렉서티 146.45\n",
      "| 에폭 3 |  반복 1041 / 1327 | 시간 159[s] | 퍼플렉서티 130.03\n",
      "| 에폭 3 |  반복 1061 / 1327 | 시간 162[s] | 퍼플렉서티 121.32\n",
      "| 에폭 3 |  반복 1081 / 1327 | 시간 165[s] | 퍼플렉서티 101.21\n",
      "| 에폭 3 |  반복 1101 / 1327 | 시간 168[s] | 퍼플렉서티 108.30\n",
      "| 에폭 3 |  반복 1121 / 1327 | 시간 170[s] | 퍼플렉서티 140.61\n",
      "| 에폭 3 |  반복 1141 / 1327 | 시간 173[s] | 퍼플렉서티 134.90\n",
      "| 에폭 3 |  반복 1161 / 1327 | 시간 177[s] | 퍼플렉서티 118.11\n",
      "| 에폭 3 |  반복 1181 / 1327 | 시간 180[s] | 퍼플렉서티 122.24\n",
      "| 에폭 3 |  반복 1201 / 1327 | 시간 183[s] | 퍼플렉서티 104.63\n",
      "| 에폭 3 |  반복 1221 / 1327 | 시간 186[s] | 퍼플렉서티 102.52\n",
      "| 에폭 3 |  반복 1241 / 1327 | 시간 189[s] | 퍼플렉서티 122.64\n",
      "| 에폭 3 |  반복 1261 / 1327 | 시간 192[s] | 퍼플렉서티 115.63\n",
      "| 에폭 3 |  반복 1281 / 1327 | 시간 195[s] | 퍼플렉서티 115.65\n",
      "| 에폭 3 |  반복 1301 / 1327 | 시간 198[s] | 퍼플렉서티 148.48\n",
      "| 에폭 3 |  반복 1321 / 1327 | 시간 201[s] | 퍼플렉서티 145.43\n",
      "퍼플렉서티 평가 중 ...\n",
      "209 / 210\n",
      "검증 퍼플렉서티:  124.67665\n",
      "--------------------------------------------------\n",
      "퍼플렉서티 평가 중 ...\n",
      "234 / 235\n",
      "테스트 퍼플렉서티:  122.07295\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common import config\n",
    "# GPU에서 실행하려면 아래 주석을 해제하세요(CuPy 필요).\n",
    "# ==============================================\n",
    "config.GPU = True\n",
    "# ==============================================\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity, to_gpu\n",
    "from dataset import ptb\n",
    "from better_rnnlm import BetterRnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 3\n",
    "max_grad = 0.25\n",
    "dropout = 0.5\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_val, _, _ = ptb.load_data('val')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "\n",
    "if config.GPU:\n",
    "    corpus = to_gpu(corpus)\n",
    "    corpus_val = to_gpu(corpus_val)\n",
    "    corpus_test = to_gpu(corpus_test)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n",
    "                time_size=time_size, max_grad=max_grad)\n",
    "\n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('검증 퍼플렉서티: ', ppl)\n",
    "\n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "\n",
    "    model.reset_state()\n",
    "    print('-' * 50)\n",
    "\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CuPy",
   "language": "python",
   "name": "cupy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
